{
  "hash": "249fa56cf691512c701683bc0ebb46af",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Supply Chain Data Analytics\nsubtitle: Analyzing and Forcasting Supermarket Sales\nauthors:\n  - name: Stan Brouwer\n    orchid: 0009-0006-3447-0096\n    affiliation: Vrije Universiteit\n    corresponding: true\n  - name: Liz Chan\n    affiliation: Master TSCM\n  - name: Maaike Lamberst\n    affiliation: Supply Chain Data analysis\n  - name: Niek Schroor\n    affiliation: Group 10\n\ndate: last-modified\nbibliography: references.bib\ncitation:\n  container-title: Earth and Space Science\nnumber-sections: true\n---\n\n\nWe analyze, forecast and interpret the [Superstore sales](https://public.tableau.com/app/sample-data/sample_-_superstore.xls) provided by [Tableau](https://public.tableau.com/app/learn/sample-data) using different statistical and machine learning methods.\n\nWe describe our work in the PDF version. However, we would like to recommend reading our quarto manuscript *here* as it contains the **relevant** R code in the Article Notebook.\n\n## Data Pre-processing\n\nThe superstore data set we selected is of high quality. Thus we do the required data pre-processing, but included the hypothetical steps we would take were our data of lower quality to communicate our understanding of the data pre-processing process.\n\nWe took the following pre-processing steps:\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\n# Clear workspace\nrm(list = ls())\n# Function to load (and install if necessary) dependencies\ninstall_and_load <- function(packages) {\n  install.packages(setdiff(packages, rownames(installed.packages())), dependencies = TRUE)\n  invisible(lapply(packages, require, character.only = TRUE))\n}\ninstall_and_load(c(\"tidyverse\", \"readxl\", \"ggplot2\", \"lubridate\", \"stats\", \"Amelia\",\"forecast\", \"tseries\", \"plotly\", \"stringr\", \"knitr\"))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: tidyverse\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: readxl\n\nLoading required package: Amelia\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'Amelia' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: Rcpp\n## \n## Amelia II: Multiple Imputation\n## (Version 1.8.3, built: 2024-11-07)\n## Copyright (C) 2005-2024 James Honaker, Gary King and Matthew Blackwell\n## Refer to http://gking.harvard.edu/amelia/ for more information\n## \nLoading required package: forecast\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'forecast' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \nLoading required package: tseries\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'tseries' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: plotly\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nLoading required package: knitr\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'knitr' was built under R version 4.3.3\n```\n\n\n:::\n:::\n\n\n-   Improved column names by removing whitespaces\n-   Removed the <code>Row_ID</code> column as it can be inferred by it's index\n-   Removed all columns with a single unique value, as storing these would be [redundant](https://few.vu.nl/~molenaar/courses/StatR/chapters/B-06-raw_data.html)\n-   Ensured machine-readable date formats in yyyy-mm-dd as these usually differ per locale.\n-   Ensured proper decimal separators\n-   calculated the number of missing values (both NA and empty string \"\") per column.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Load the data\nsuppressWarnings({data <- read_excel(\"data/sample_-_superstore.xls\")}) # The Postal code column is stored as 'text' but coerced to numeric, causing warnings which we suppress\n\n# Improve column names (replace \" \"with \"_\")\ncolnames(data) <- str_replace_all(colnames(data), \" \", \"_\")\n\n# Remove the 'Row_ID' column as it can be inferred by it's index\ndata <- subset(data, select = -`Row_ID`)\n\n# Remove all columns that have only one unique value, as storing these would be redundant\ndata <- data[, sapply(data, function(col) length(unique(col)) > 1)]\n\n# Ensure a machine-readable date format as these are usually horrible in excel files\ndata$Order_Date <- as.Date(data$Order_Date, format = \"%Y-%m-%d\")\ndata$Ship_Date <- as.Date(data$Ship_Date, format = \"%Y-%m-%d\")\n\n# The readxl package by default uses the correct decimal separator (as opposed to base R)\n\n# Calculate the number of missing values per column.\n# The sample dates are likely in Unix time, and when these are converted to R date objects they are stored as Date objects (which are represented by 'double' datatypes). Comparing these dates to characters (empty strings) results in NA values. Thus we only check date values for NA. As Date objects are stored as doubles within R (amount of days since 1970-01-01), we can't check numeric columns for \" \" either. We thus only check character columns for \" \".\nmissing_values <- sapply(data, function(col) {\n  if (inherits(col, \"Date\")) {\n    sum(is.na(col))\n  } else if (is.character(col)) {\n    sum(is.na(col) | col == \"\")\n  } else {\n    sum(is.na(col))\n  }\n})\n\nif (sum(missing_values) == 0) {\n  print(\"No missing values\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"No missing values\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Optionally, print the missing values as a nice table using knitr\n# Convert the result into a data frame (table)\nmissing_values_table <- data.frame(\n  Column = names(missing_values),\n  Missing_or_Empty = missing_values\n)\n\n# Note that there are no missing values, thus we do not print them\n# kable(missing_values_table, caption = \"Missing or Empty Values in Columns\", format = \"pipe\")\nrm(missing_values, missing_values_table)\n```\n:::\n\n\nWe also ran some descriptive statistics to check unlikely or impossible values, outliers, means, etc.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Select only numerical columns\nnumerical_data <- data %>% select_if(is.numeric)\n\n# Apply sapply to calculate descriptive statistics for each numeric column\ndescriptive_stats <- sapply(numerical_data, function(col) {\n  # Remove NA values\n  col <- na.omit(col)\n  \n  # Calculate basic statistics\n  min_val <- min(col)\n  max_val <- max(col)\n  mean_val <- mean(col)\n  median_val <- median(col)\n  \n  # 95% Confidence Interval (assuming normal distribution)\n  se <- sd(col) / sqrt(length(col))  # Standard error\n  ci_lower <- mean_val - 1.96 * se  # Lower bound of 95% CI\n  ci_upper <- mean_val + 1.96 * se  # Upper bound of 95% CI\n  \n  # Calculate outliers (using 1.5 * IQR rule)\n  Q1 <- quantile(col, 0.25)\n  Q3 <- quantile(col, 0.75)\n  IQR <- Q3 - Q1\n  outliers <- sum(col < (Q1 - 1.5 * IQR) | col > (Q3 + 1.5 * IQR))  # Number of outliers\n  \n  # Return the statistics as a named vector\n  return(c(Min = min_val, \n           Mean = mean_val, \n           Max = max_val, \n           Median = median_val, \n           `95% CI Lower` = ci_lower, \n           `95% CI Upper` = ci_upper, \n           Outliers = outliers))\n})\nhead(data,5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 19\n  Order_ID     Order_Date Ship_Date  Ship_Mode Customer_ID Customer_Name Segment\n  <chr>        <date>     <date>     <chr>     <chr>       <chr>         <chr>  \n1 CA-2016-152… 2016-11-08 2016-11-11 Second C… CG-12520    Claire Gute   Consum…\n2 CA-2016-152… 2016-11-08 2016-11-11 Second C… CG-12520    Claire Gute   Consum…\n3 CA-2016-138… 2016-06-12 2016-06-16 Second C… DV-13045    Darrin Van H… Corpor…\n4 US-2015-108… 2015-10-11 2015-10-18 Standard… SO-20335    Sean O'Donne… Consum…\n5 US-2015-108… 2015-10-11 2015-10-18 Standard… SO-20335    Sean O'Donne… Consum…\n# ℹ 12 more variables: City <chr>, State <chr>, Postal_Code <dbl>,\n#   Region <chr>, Product_ID <chr>, Category <chr>, `Sub-Category` <chr>,\n#   Product_Name <chr>, Sales <dbl>, Quantity <dbl>, Discount <dbl>,\n#   Profit <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n\nThere is some more processing to do, such as removing outliers. However, by doing so we impose our own assumptions on the data (possibly the outliers are actual sales?). We will visualize and qualitatively evaluate the data first, and then decide what other processing steps to take. \n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Display the first 5 rows of the data in a nice table with kable\nkable(head(data,5), caption = \"First 5 Rows of the Data\", format = \"pipe\")\n```\n\n::: {.cell-output-display}\n\n\nTable: First 5 Rows of the Data\n\n|Order_ID       |Order_Date |Ship_Date  |Ship_Mode      |Customer_ID |Customer_Name   |Segment   |City            |State      | Postal_Code|Region |Product_ID      |Category        |Sub-Category |Product_Name                                                |    Sales| Quantity| Discount|    Profit|\n|:--------------|:----------|:----------|:--------------|:-----------|:---------------|:---------|:---------------|:----------|-----------:|:------|:---------------|:---------------|:------------|:-----------------------------------------------------------|--------:|--------:|--------:|---------:|\n|CA-2016-152156 |2016-11-08 |2016-11-11 |Second Class   |CG-12520    |Claire Gute     |Consumer  |Henderson       |Kentucky   |       42420|South  |FUR-BO-10001798 |Furniture       |Bookcases    |Bush Somerset Collection Bookcase                           | 261.9600|        2|     0.00|   41.9136|\n|CA-2016-152156 |2016-11-08 |2016-11-11 |Second Class   |CG-12520    |Claire Gute     |Consumer  |Henderson       |Kentucky   |       42420|South  |FUR-CH-10000454 |Furniture       |Chairs       |Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back | 731.9400|        3|     0.00|  219.5820|\n|CA-2016-138688 |2016-06-12 |2016-06-16 |Second Class   |DV-13045    |Darrin Van Huff |Corporate |Los Angeles     |California |       90036|West   |OFF-LA-10000240 |Office Supplies |Labels       |Self-Adhesive Address Labels for Typewriters by Universal   |  14.6200|        2|     0.00|    6.8714|\n|US-2015-108966 |2015-10-11 |2015-10-18 |Standard Class |SO-20335    |Sean O'Donnell  |Consumer  |Fort Lauderdale |Florida    |       33311|South  |FUR-TA-10000577 |Furniture       |Tables       |Bretford CR4500 Series Slim Rectangular Table               | 957.5775|        5|     0.45| -383.0310|\n|US-2015-108966 |2015-10-11 |2015-10-18 |Standard Class |SO-20335    |Sean O'Donnell  |Consumer  |Fort Lauderdale |Florida    |       33311|South  |OFF-ST-10000760 |Office Supplies |Storage      |Eldon Fold 'N Roll Cart System                              |  22.3680|        2|     0.20|    2.5164|\n\n\n:::\n:::\n\n\n\n\n## Section\n\nThis is a simple placeholder for the manuscript's main document [@knuth84].\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 + 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n:::\n\n\n\n\n\n## Introduction\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\neruptions <- c(1492, 1585, 1646, 1677, 1712, 1949, 1971, 2021)\nn_eruptions <- length(eruptions)\n```\n:::\n\n::: {#cell-fig-timeline .cell}\n\n```{.r .cell-code .hidden}\npar(mar = c(3, 1, 1, 1) + 0.1)\nplot(eruptions, rep(0, n_eruptions), \n  pch = \"|\", axes = FALSE)\naxis(1)\nbox()\n```\n\n::: {.cell-output-display}\n![Timeline of recent earthquakes on La Palma](index_files/figure-html/fig-timeline-1.png){#fig-timeline fig-alt='An event plot of the years of the last 8 eruptions on La Palma.' width=576}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\navg_years_between_eruptions <- mean(diff(eruptions[-n_eruptions]))\navg_years_between_eruptions\n```\n\n::: {.cell-output .cell-output-stdout .hidden}\n\n```\n[1] 79.83333\n```\n\n\n:::\n:::\n\n\nBased on data up to and including 1971, eruptions on La Palma happen every 79.8 years on average.\n\nStudies of the magma systems feeding the volcano, such as @marrero2019, have proposed that there are two main magma reservoirs feeding the Cumbre Vieja volcano; one in the mantle (30-40km depth) which charges and in turn feeds a shallower crustal reservoir (10-20km depth).\n\nEight eruptions have been recorded since the late 1400s (@fig-timeline).\n\nData and methods are discussed in @sec-data-methods.\n\nLet $x$ denote the number of eruptions in a year. Then, $x$ can be modeled by a Poisson distribution\n\n$$\np(x) = \\frac{e^{-\\lambda} \\lambda^{x}}{x !}\n$$ {#eq-poisson}\n\nwhere $\\lambda$ is the rate of eruptions per year. Using @eq-poisson, the probability of an eruption in the next $t$ years can be calculated.\n\n| Name                 | Year   |\n| -------------------- | ------ |\n| Current              | 2021   |\n| Teneguía             | 1971   |\n| Nambroque            | 1949   |\n| El Charco            | 1712   |\n| Volcán San Antonio   | 1677   |\n| Volcán San Martin    | 1646   |\n| Tajuya near El Paso  | 1585   |\n| Montaña Quemada      | 1492   |\n\n: Recent historic eruptions on La Palma {#tbl-history}\n\n@tbl-history summarises the eruptions recorded since the colonization of the islands by Europeans in the late 1400s.\n\n![Map of La Palma](images/la-palma-map.png){#fig-map}\n\nLa Palma is one of the west most islands in the Volcanic Archipelago of the Canary Islands (@fig-map). \n\n\n{{< embed notebooks/explore-earthquakes.qmd#fig-spatial-plot >}}\n\n\n\n@fig-spatial-plot shows the location of recent Earthquakes on La Palma.\n\n## Data & Methods {#sec-data-methods}\n\n## Conclusion\n\n## References {.unnumbered}\n\n:::{#refs}\n\n:::",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}