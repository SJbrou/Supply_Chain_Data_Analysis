{
  "hash": "ffed47fa571394b066a70e2fc5a18c90",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Supply Chain Data Analytics\nsubtitle: Analyzing and Forcasting Supermarket Sales\nauthors:\n  - name: Stan Brouwer (2671939)\n    orchid: 0009-0006-3447-0096\n    affiliation: Vrije Universiteit\n    corresponding: true\n  - name: Liz Chen (2840693)\n    affiliation: Master TSCM\n  - name: Maaike Lamberts (2854979)\n    affiliation: Supply Chain Data analysis\n  - name: Niek Schroor (2786837)\n    affiliation: Group 10\n\ndate: last-modified\nbibliography: references.bib\nnumber-sections: true\n\noutput:\n  html: default\n  pdf: default\nprefer-html: true\n---\n\n\n\n\n\n## Data selection\n\nWe analyze, forecast and interpret the [Superstore sales](https://public.tableau.com/app/sample-data/sample_-_superstore.xls) provided by [Tableau](https://public.tableau.com/app/learn/sample-data) using different statistical and machine learning methods.\n\nThe dataset provided contains information about products, sales and profits of a fictitious US company. The dataset contains about 10,000 rows with 1,850 unique product names and 17 product subcategories, covering four consecutive years on a daily basis.\n\nWe describe our work in the PDF version. However, we would like to recommend reading our quarto manuscript *here* as it contains the **relevant** R code in the Article Notebook.\n\n## Data Pre-processing\n\nThe superstore data set we selected is of high quality: At first glance (which needs to be verified during the visualization), the data appears to have been recorded regularly and without interruptions. There is no sign of a sudden structural change. Since the data are consumer products, it should contain both trends and seasonality.\nNevertheless, we have included hypothetical steps to demonstrate our understanding of the data preprocessing procedure. In detail, we did:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Clear workspace\nrm(list = ls())\n# Function to load (and install if necessary) dependencies\ninstall_and_load <- function(packages) {\n  install.packages(setdiff(packages, rownames(installed.packages())), dependencies = TRUE)\n  invisible(lapply(packages, require, character.only = TRUE))\n}\ninstall_and_load(c(\"tidyverse\", \"readxl\", \"ggplot2\", \"lubridate\", \"stats\", \"Amelia\",\"forecast\", \"tseries\", \"plotly\", \"stringr\", \"knitr\", \"kableExtra\"))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: tidyverse\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.4     v readr     2.1.5\nv forcats   1.0.0     v stringr   1.5.1\nv ggplot2   3.5.1     v tibble    3.2.1\nv lubridate 1.9.3     v tidyr     1.3.1\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: readxl\n\nLoading required package: Amelia\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'Amelia' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: Rcpp\n## \n## Amelia II: Multiple Imputation\n## (Version 1.8.3, built: 2024-11-07)\n## Copyright (C) 2005-2024 James Honaker, Gary King and Matthew Blackwell\n## Refer to http://gking.harvard.edu/amelia/ for more information\n## \nLoading required package: forecast\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'forecast' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \nLoading required package: tseries\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'tseries' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: plotly\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nLoading required package: knitr\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'knitr' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: kableExtra\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n```\n\n\n:::\n:::\n\n\n\n\n\n-   Remove whitespaces from column names\n-   Remove the <code>Row_ID</code> column as it can be inferred by it's index\n-   Remove all columns with a single unique value, as storing these would be [redundant](https://few.vu.nl/~molenaar/courses/StatR/chapters/B-06-raw_data.html)\n-   Ensure machine-readable date formats in <code>yyyy-mm-dd</code> as these usually differ per locale.\n-   Ensure proper decimal separators\n-   Calculate the number of missing values (both NA and empty string \"\") per column.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Load the data\nsuppressWarnings({data <- read_excel(\"data/sample_-_superstore.xls\")}) # The Postal code column is stored as 'text' but coerced to numeric, causing warnings which we suppress\n\n# Improve column names\ncolnames(data) <- str_replace_all(colnames(data), \" \", \"_\")\ncolnames(data) <- str_replace_all(colnames(data), \"-\", \"_\")\n\n# Remove the 'Row_ID' column as it can be inferred by it's index\ndata <- subset(data, select = -`Row_ID`)\n\n# Remove all columns that have only one unique value, as storing these would be redundant\ndata <- data[, sapply(data, function(col) length(unique(col)) > 1)]\n\n# Ensure a machine-readable date format as these are usually horrible in excel files\ndata$Order_Date <- as.Date(data$Order_Date, format = \"%Y-%m-%d\")\ndata$Ship_Date <- as.Date(data$Ship_Date, format = \"%Y-%m-%d\")\n\n# The readxl package by default uses the correct decimal separator (as opposed to base R)\n\n# Calculate the number of missing values per column.\n# Origional dates and R date objects are in unix time, which return NA when compared to text (empty string). These dates are stored as 'double' datatype, Thus we check character columns for empty strings, and all columns for NA values. \nmissing_values <- sapply(data, function(col) {\n  if (inherits(col, \"Date\")) {\n    sum(is.na(col))\n  } else if (is.character(col)) {\n    sum(is.na(col) | col == \"\")\n  } else {\n    sum(is.na(col))\n  }\n})\n\n# sum(missing_values) returns 0!\n\n# Optionally, print the missing values as a nice table\nmissing_values_table <- data.frame(\n  Column = names(missing_values),\n  Missing_or_Empty = missing_values\n)\n# Note that there are no missing values, thus we do not print them\n# kable(missing_values_table, caption = \"Missing or Empty Values in Columns\", format = \"pipe\")\n\n\nrm(missing_values, missing_values_table)\n```\n:::\n\n\n\n\n\nAfter these steps (and transposing the table for better document formatting), the data looks as follows:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nkable(t(head(data, 3)), caption = \"First 3 Rows of the Data (Transposed)\", format = \"markdown\")\n```\n\n::: {.cell-output-display}\n\n\nTable: First 3 Rows of the Data (Transposed)\n\n|              |                                  |                                                            |                                                          |\n|:-------------|:---------------------------------|:-----------------------------------------------------------|:---------------------------------------------------------|\n|Order_ID      |CA-2016-152156                    |CA-2016-152156                                              |CA-2016-138688                                            |\n|Order_Date    |2016-11-08                        |2016-11-08                                                  |2016-06-12                                                |\n|Ship_Date     |2016-11-11                        |2016-11-11                                                  |2016-06-16                                                |\n|Ship_Mode     |Second Class                      |Second Class                                                |Second Class                                              |\n|Customer_ID   |CG-12520                          |CG-12520                                                    |DV-13045                                                  |\n|Customer_Name |Claire Gute                       |Claire Gute                                                 |Darrin Van Huff                                           |\n|Segment       |Consumer                          |Consumer                                                    |Corporate                                                 |\n|City          |Henderson                         |Henderson                                                   |Los Angeles                                               |\n|State         |Kentucky                          |Kentucky                                                    |California                                                |\n|Postal_Code   |42420                             |42420                                                       |90036                                                     |\n|Region        |South                             |South                                                       |West                                                      |\n|Product_ID    |FUR-BO-10001798                   |FUR-CH-10000454                                             |OFF-LA-10000240                                           |\n|Category      |Furniture                         |Furniture                                                   |Office Supplies                                           |\n|Sub_Category  |Bookcases                         |Chairs                                                      |Labels                                                    |\n|Product_Name  |Bush Somerset Collection Bookcase |Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back |Self-Adhesive Address Labels for Typewriters by Universal |\n|Sales         |261.96                            |731.94                                                      |14.62                                                     |\n|Quantity      |2                                 |3                                                           |2                                                         |\n|Discount      |0                                 |0                                                           |0                                                         |\n|Profit        |41.9136                           |219.5820                                                    |6.8714                                                    |\n\n\n:::\n:::\n\n\n\n\n\nWe did not find any missing values, confirming the quality of the data set. There is some more processing to do, for instance the removal of outliers. However, by doing so we impose our own assumptions on the data. Let's start by evaluating the descriptive statistics of our data and check if further processing is required.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ndescriptive_statistics <- function(column) {\n  if (is.numeric(column)) {\n    stats <- list(\n      Min = min(column, na.rm = TRUE), # Note that handling NA values increases robustness (and I copied the funciton from some of my earlier work)\n      Max = max(column, na.rm = TRUE),\n      Mean = mean(column, na.rm = TRUE),\n      Median = median(column, na.rm = TRUE),\n      StdDev = sd(column, na.rm = TRUE)\n    )\n  } else if (inherits(column, \"Date\")) {\n    stats <- list(\n      Earliest = format(min(column, na.rm = TRUE), \"%Y-%m-%d\"),\n      Latest = format(max(column, na.rm = TRUE), \"%Y-%m-%d\")\n    )\n  } else if (is.character(column)) {\n    stats <- list(\n      Unique = length(unique(column)),\n      Mode = names(sort(table(column), decreasing = TRUE)[1])\n    )\n  } else {\n    stats <- NULL\n  }\n  return(stats)\n}\n\n# Call function on dataframe\ndescriptive_stats <- lapply(data, descriptive_statistics)\n\n# Separate to tables dependent on data type\nnumeric_stats <- as.data.frame(do.call(rbind, lapply(names(data), function(col_name) {\n  if (is.numeric(data[[col_name]])) {\n    c(Column = col_name, descriptive_stats[[col_name]])\n  }\n})), stringsAsFactors = FALSE)\ndate_stats <- as.data.frame(do.call(rbind, lapply(names(data), function(col_name) {\n  if (inherits(data[[col_name]], \"Date\")) {\n    c(Column = col_name, descriptive_stats[[col_name]])\n  }\n})), stringsAsFactors = FALSE)\ncharacter_stats <- as.data.frame(do.call(rbind, lapply(names(data), function(col_name) {\n  if (is.character(data[[col_name]])) {\n    c(Column = col_name, descriptive_stats[[col_name]])\n  }\n})), stringsAsFactors = FALSE)\n```\n:::\n\n::: {.cell Label='Descriptive_Output_tables'}\n\n```{.r .cell-code .hidden}\nkable(\n  numeric_stats,\n  caption = \"Descriptive Statistics for Numeric Columns\",\n  format = \"pipe\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Descriptive Statistics for Numeric Columns\n\n|Column      |Min       |Max      |Mean      |Median  |StdDev   |\n|:-----------|:---------|:--------|:---------|:-------|:--------|\n|Postal_Code |1040      |99301    |55190.38  |56430.5 |32063.69 |\n|Sales       |0.444     |22638.48 |229.858   |54.49   |623.2451 |\n|Quantity    |1         |14       |3.789574  |3       |2.22511  |\n|Discount    |0         |0.8      |0.1562027 |0.2     |0.206452 |\n|Profit      |-6599.978 |8399.976 |28.6569   |8.6665  |234.2601 |\n\n\n:::\n\n```{.r .cell-code .hidden}\nkable(\n  date_stats,\n  caption = \"Descriptive Statistics for Date Columns\",\n  format = \"pipe\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Descriptive Statistics for Date Columns\n\n|Column     |Earliest   |Latest     |\n|:----------|:----------|:----------|\n|Order_Date |2014-01-03 |2017-12-30 |\n|Ship_Date  |2014-01-07 |2018-01-05 |\n\n\n:::\n:::\n\n\n\n\nWe inspect the orders with the lowest and highest Sales amount (in USD). The most expensive orders were professional printers, cameras and teleconferencing units with high unit prices. The orders with the lowest sales amount were often binders and had a high Discount rate.\n\nInterestingly there are orders with a negative profit. They typically have high Discount rates and often concern the same item, such as the “Cubify CubeX 3D Printer Triple Head Print”. The orders with a negative Profit were often part of a larger order (for instance CA-2016-108196), and placed by customers with multiple orders. We suspect these negative Profit's to be caused by items of lower quality that receive discounts, general discount codes, or volume discounts. However, due to the high discounts especially on orders with negative profit, we assume these to be valid orders. \n\n** Some negative profit products **\n\nIn figure x we plotted the quantities of the most sold products. Unfortunately, the sold quantities of individual products were too low to determine any meaningful trends.\n\n\n\n\n\n::: {.cell warnng='false'}\n\n```{.r .cell-code .hidden}\n# Optionally: print top 10 sale quantity barplot\n# # Sum of Quantity for top products\n# top_products <- data %>%\n#   group_by(Product_Name) %>%\n#   summarize(total_quantity = sum(Quantity, na.rm = TRUE)) %>%\n#   arrange(desc(total_quantity)) %>%\n#   slice_head(n = 10) %>% \n#   mutate(ProdName8 = substr(Product_Name, 1, 8)) # Truncate product names to the first 8 characters. Long names mess up formatting\n# \n# # Plot\n# ggplot(top_products, aes(x = reorder(ProdName8, -total_quantity), y = total_quantity)) +\n#   geom_bar(stat = \"identity\", fill = \"steelblue\") +\n#   labs(title = \"Top 20 Most Sold Products\",\n#        x = \"Product ID\",\n#        y = \"Total Quantity\") +\n#   theme_minimal() +\n#   coord_flip()\n\n# Aggregate quantity by Product Name and Order Date\ntime_series_data <- data %>%\n  group_by(Product_Name, Order_Date) %>%\n  summarize(total_quantity = sum(Quantity, na.rm = TRUE)) %>%\n  ungroup()\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'Product_Name'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Filter by total quantity sold \ntop_products <- time_series_data %>%\n  group_by(Product_Name) %>%\n  summarize(total_quantity = sum(total_quantity)) %>%\n  arrange(desc(total_quantity)) %>%\n  slice_head(n = 10)\n\n# Filter the time-series data\nfiltered_time_series_data <- time_series_data %>%\n  filter(Product_Name %in% top_products$Product_Name) %>%\n  mutate(ProdName10 = substr(Product_Name, 1, 10)) # Product names can be quite long and mess up layouts. Lets only plot the first 10 chars.\n\n# Here we do some special plotting. We want to show the plot with only one selected line by default, but make sure that the other 9 top sold products can be selected. We first create the ggplotly object, and than modify the visibility of the traces\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\np_ly <- ggplotly(ggplot(filtered_time_series_data, aes(x = Order_Date, y = total_quantity, color = ProdName10)) +\n  geom_line(size = 1) +\n  labs(title = \"Quantity Sold Over Time per Product\",\n       x = \"Order Date\",\n       y = \"Quantity Sold\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  scale_color_discrete(name = \"Product Name\"))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` instead.\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nfor (i in seq_along(p_ly$x$data)) {\n  if (i == 1) {\n    p_ly$x$data[[i]]$visible <- TRUE\n  } else {\n    p_ly$x$data[[i]]$visible <- \"legendonly\"\n  }\n}\n\np_ly\n```\n\n::: {.cell-output-display}\n![Figure X Sale quantity of the most popular products](index_files/figure-pdf/Top_Products_Quantity-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\nOur proposed workaround is to aggregate <code>Product_Name</code> by <code>Sub_Category</code>, and treat it as a single product for the rest of the assignment, which we plotted in figure X.\n\n\n\n\n\n::: {.cell fig-caption='Aggregated Sub_Category sales (toggle )'}\n\n```{.r .cell-code .hidden}\ntop_categories <- data %>%\n  count(Sub_Category, sort = TRUE)\n\ntop_10_categories <- top_categories$Sub_Category[0:10]\n\n# Filter the data for  top 10 products\ntop_10_data <- data %>% filter(Sub_Category %in% top_10_categories)\n\n# calculate sales per month\ntop_10_data <- top_10_data %>%\n  mutate(Month = floor_date(Order_Date, unit = \"month\"))\n\n# Aggregate data by month for each sub-category\ntop_10_data_aggregated <- top_10_data %>%\n  group_by(Month, Sub_Category) %>%\n  summarise(Sales_Count = n(), .groups = 'drop')\n\n# Some special interactive plot formatting (see previous plot)\np_ly <- ggplotly(ggplot(top_10_data_aggregated, aes(x = Month, y = Sales_Count, color = Sub_Category, group = Sub_Category)) +\n    geom_line(size = 1) +\n    geom_point(size = 2) +\n    labs(title = \"Monthly Sales for the Top 3 Most Sold Sub Categories\",\n         x = \"Month\",\n         y = \"Sales Count\",\n         color = \"Sub Category\") +\n    theme_minimal())\n\nfor (i in seq_along(p_ly$x$data)) {\n  if (i == 1) {\n    p_ly$x$data[[i]]$visible <- TRUE\n  } else {\n    p_ly$x$data[[i]]$visible <- \"legendonly\"\n  }\n}\n\np_ly\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/Aggregated_Sub_Category_sales-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\nThis aggregated Quantity starts to show trends and seasonality, and is much more useful to base predictions on! We will use these aggregated sub-categories for the rest of the assignment.\n\nTo properly finish our data preprocessing we ran some statistics on Quantity aggregated by Sub_Category. Table x contains some descriptive statistics.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(dplyr)\nlibrary(kableExtra)\n\n# Summarize the data\noutlier_summary <- data %>%\n  group_by(Sub_Category) %>%\n  summarize(\n    Min = round(min(Quantity), 2),\n    Mean = round(mean(Quantity), 2),\n    Max = round(max(Quantity), 2),\n    Sd = round(sd(Quantity), 2),\n    CI_lower = round(Mean - 1.96 * (Sd / sqrt(n())), 2),\n    CI_upper = round(Mean + 1.96 * (Sd / sqrt(n())), 2),\n    .groups = \"drop\"\n  )\n\n# Output tables\nkable(\n  outlier_summary,\n  caption = \"Statistics for Sub_Category quantity\",\n  format = \"pipe\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Statistics for Sub_Category quantity\n\n|Sub_Category | Min| Mean| Max|   Sd| CI_lower| CI_upper|\n|:------------|---:|----:|---:|----:|--------:|--------:|\n|Accessories  |   1| 3.84|  14| 2.28|     3.68|     4.00|\n|Appliances   |   1| 3.71|  14| 2.12|     3.52|     3.90|\n|Art          |   1| 3.77|  14| 2.13|     3.62|     3.92|\n|Binders      |   1| 3.92|  14| 2.29|     3.80|     4.04|\n|Bookcases    |   1| 3.81|  13| 2.28|     3.51|     4.11|\n|Chairs       |   1| 3.82|  14| 2.28|     3.64|     4.00|\n|Copiers      |   1| 3.44|   9| 1.83|     3.01|     3.87|\n|Envelopes    |   1| 3.57|   9| 2.05|     3.32|     3.82|\n|Fasteners    |   1| 4.21|  14| 2.41|     3.89|     4.53|\n|Furnishings  |   1| 3.72|  14| 2.16|     3.58|     3.86|\n|Labels       |   1| 3.85|  14| 2.35|     3.61|     4.09|\n|Machines     |   1| 3.83|  11| 2.17|     3.43|     4.23|\n|Paper        |   1| 3.78|  14| 2.23|     3.66|     3.90|\n|Phones       |   1| 3.70|  14| 2.19|     3.56|     3.84|\n|Storage      |   1| 3.73|  14| 2.19|     3.58|     3.88|\n|Supplies     |   1| 3.41|  10| 1.84|     3.15|     3.67|\n|Tables       |   1| 3.89|  13| 2.45|     3.62|     4.16|\n\n\n:::\n:::\n\n\n\n\n\nThe statistics for <code>Quantity</code> aggregated by <code>Sub_Category</code> looks valid. We can visualize it as histogram and check for anomalies. Figure y contains histograms of <code>Quantity</code> per <code>Sub_Category</code>.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nsub_categories <- unique(data$Sub_Category)\n\np <- plot_ly()\nfor (i in seq_along(sub_categories)) {\n  sub <- sub_categories[i]\n  subset_data <- data %>% filter(Sub_Category == sub)\n  p <- add_trace(\n    p,\n    x = subset_data$Quantity,\n    type = \"histogram\",\n    name = sub,\n    visible = ifelse(i == 1, TRUE, FALSE)\n  )\n}\n\n# We add a drop down menu for Sub_Category as toggling visibility in default ggplot2 adds the histograms up. Instead we want to be able to show each histogram seperately. \ndropdown_buttons <- lapply(seq_along(sub_categories), function(i) {\n  list(\n    method = \"update\",\n    args = list(\n      list(visible = lapply(seq_along(sub_categories), function(j) j == i)),\n      list(xaxis = list(title = \"Quantity\", autorange = TRUE), \n           yaxis = list(title = \"Frequency\", autorange = TRUE))\n    ),\n    label = sub_categories[i]\n  )\n})\n\n# Style drop down layout\np <- p %>%\n  layout(\n    title = \"Distribution of Quantity Sold per Order by Sub Category\",\n    xaxis = list(title = \"Quantity\"),\n    yaxis = list(title = \"Frequency\"),\n    showlegend = FALSE,  # Drop down instead of legend\n    updatemenus = list(\n      list(\n        type = \"dropdown\",\n        buttons = dropdown_buttons,\n        direction = \"down\",\n        x = 0.99,\n        y = 0.99,\n        showactive = TRUE,\n        xanchor = \"left\",\n        yanchor = \"top\"\n      )\n    )\n  )\np\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/sub_category_histograms-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\nThe histograms show that the quantities a right-skewed distributed. This is to be expected since most orders contain only a small number of items. We will not remove the outliers with large quantities since they appear valid..\n\n\n## Forecasting Method Evaluation\n\n### Forecasting top 3 product categories (4a)\n\nLet's forecast sold quantities for the three most sold sub-categories:\n\nThe steps taken for data preparation were:\n\n-   Identifying Top Subcategories: The top three subcategories are selected from our dataset based on their sold quantities. The top three were: Binders, furnishing and paper.\n-   The sold quantities are aggregated monthly to create a time series object which we can use in the forecasting.\n-   A KPSS showed that the data is non stationary. First-order differencing is applied to transform the data from non-stationary to stationary. The KPSS results in a p-value >0.05 showing the stationarity. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntop_categories <- data %>%\n  group_by(Sub_Category) %>%\n  summarise(Total_Quantity = sum(Quantity)) %>%\n  arrange(desc(Total_Quantity))\ntop_3_subcategories <- top_categories$Sub_Category[0:3]\n\ntop_3_data <- data %>% filter(Sub_Category %in% top_3_subcategories)\n\n# calculate sales per month\ntop_3_data <- top_3_data %>%\n  mutate(Month = floor_date(Order_Date, unit = \"month\"))\n\n# Aggregate data by month for each product\ntop_3_data_aggregated <- top_3_data %>%\n  group_by(Month, Sub_Category) %>%\n  summarise(Sales_Count = n(), .groups = 'drop')\n\n# Create a time series object for each product\nts_data <- top_3_data_aggregated %>%\n  pivot_wider(names_from = Sub_Category, values_from = Sales_Count, values_fill = 0) %>%\n  select(-Month) %>%\n  as.matrix()\n\nts_data <- ts(ts_data, start = c(2014, 1), end = c(2017, 12), frequency = 12) # @Stan This appears to be duplicate code?\nts_list <- list()\nfor (subcategory in top_3_subcategories) {\n  # Filter data for the subcategory\n  subcategory_data <- top_3_data_aggregated %>% filter(Sub_Category == subcategory)\n  ts_list[[subcategory]] <- ts(subcategory_data$Sales_Count,\n                                start = c(2014, 1),\n                                end = c(2017, 12),\n                                frequency = 12)\n}\n\n\n# forecasting methods on top 3 sub-categories\nforecast_results <- list()\n\nfor (subcategory in names(ts_list)) {\n  ts_current <- ts_list[[subcategory]]\n  train_size <- floor(0.7 * length(ts_current))\n  train_ts <- window(ts_current, end = c(2014 + (train_size - 1) %/% 12, (train_size - 1) %% 12 + 1))\n  test_ts <- window(ts_current, start = c(2014 + train_size %/% 12, train_size %% 12 + 1))\n\n  arima_model <- auto.arima(train_ts)\n  arima_forecast <- forecast(arima_model, h = length(test_ts))\n  arima_accuracy <- accuracy(arima_forecast, test_ts)\n\n  hw_model <- HoltWinters(train_ts)\n  hw_forecast <- forecast(hw_model, h = length(test_ts))\n  hw_accuracy <- accuracy(hw_forecast, test_ts)\n\n  ets_model <- ets(train_ts)\n  ets_forecast <- forecast(ets_model, h = length(test_ts))\n  ets_accuracy <- accuracy(ets_forecast, test_ts)\n\n  forecast_results[[subcategory]] <- list(\n    ARIMA = list(Model = arima_model, Forecast = arima_forecast, Accuracy = arima_accuracy),\n    HoltWinters = list(Model = hw_model, Forecast = hw_forecast, Accuracy = hw_accuracy),\n    ETS = list(Model = ets_model, Forecast = ets_forecast, Accuracy = ets_accuracy)\n  )\n}\n\n\n# For formatting, we ommitted almost all output. You can uncomment the code and check your output if you like.\n\n# # Step 5: Print results\n#  for (subcategory in names(forecast_results)) {\n#   cat(\"\\n\\nResults for Sub_Category:\", subcategory, \"\\n\")\n# \n#   cat(\"\\nARIMA Accuracy:\\n\")\n#   print(forecast_results[[subcategory]]$ARIMA$Accuracy)\n# \n#   cat(\"\\nHolt-Winters Accuracy:\\n\")\n#   print(forecast_results[[subcategory]]$HoltWinters$Accuracy)\n# \n#   cat(\"\\nETS Accuracy:\\n\")\n#   print(forecast_results[[subcategory]]$ETS$Accuracy)\n# }\n```\n:::\n\n\n\n\n\nThree models are applied to each subcategory to forecast it. The models we use are: ARIMA, Holt-Winters and ETS. We have chosen these models because of their level of suitability for discrete time series data with all different levels of trend and seasonality. To evaluate the methods and its effectiveness , the data is split into a training set (70%) and testing set (30%). \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Lets plot the results\nfor (subcategory in names(forecast_results)) {\n  ts_current <- ts_list[[subcategory]]\n  train_size <- floor(0.7 * length(ts_current))\n  test_ts <- window(ts_current, start = c(2014 + train_size %/% 12, train_size %% 12 + 1))\n  arima_forecast <- forecast_results[[subcategory]]$ARIMA$Forecast\n  hw_forecast <- forecast_results[[subcategory]]$HoltWinters$Forecast\n  ets_forecast <- forecast_results[[subcategory]]$ETS$Forecast\n  \n  # Combined plot\n  plot(arima_forecast$mean, col = \"blue\", lwd = 2, \n       ylim = range(c(arima_forecast$mean, hw_forecast$mean, ets_forecast$mean, test_ts)),\n       main = paste(\"Combined Forecasts for\", subcategory, \"before differencing\"),\n       xlab = \"Time\", ylab = \"Forecasted Values\")\n  lines(test_ts, col = \"red\", lty = 2, lwd = 2)\n  lines(hw_forecast$mean, col = \"green\", lwd = 2)\n  lines(ets_forecast$mean, col = \"purple\", lwd = 2)\n  legend(\"topleft\", legend = c(\"ARIMA\", \"Holt-Winters\", \"ETS\", \"Test Data\"),\n         col = c(\"blue\", \"green\", \"purple\", \"red\"), lty = c(1, 1, 1, 2), lwd = 2)\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/Results1-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/Results1-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/Results1-3.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\nTo assess the results, we use the following performance metrics: ME, RMSE, MAE and MAPE. They are calculated for the training and testing phases of the forecast. \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Lets plot it as an table\n# As the relevant data is stored in lists nested in lists nested in lists nested in lists, this was some work\nresults_table <- data.frame(\n  Sub_Category = character(),\n  Method = character(),\n  Dataset = character(),\n  ME = numeric(),\n  RMSE = numeric(),\n  MAE = numeric(),\n  MPE = numeric(),\n  MAPE = numeric(),\n  MASE = numeric(),\n  ACF1 = numeric(),\n  Theil_U = numeric(),\n  stringsAsFactors = FALSE\n)\n\nfor (subcategory in names(forecast_results)) {\n  subcategory_results <- forecast_results[[subcategory]]\n  for (method in c(\"ARIMA\", \"HoltWinters\", \"ETS\")) {\n    if (!is.null(subcategory_results[[method]])) {\n      accuracy_metrics <- subcategory_results[[method]]$Accuracy\n      for (dataset in rownames(accuracy_metrics)) {\n        row <- data.frame(\n          Sub_Category = subcategory,\n          Method = method,\n          Dataset = dataset,\n          ME = round(accuracy_metrics[dataset, \"ME\"], 3),\n          RMSE = round(accuracy_metrics[dataset, \"RMSE\"], 3),\n          MAE = round(accuracy_metrics[dataset, \"MAE\"], 3),\n          MPE = round(accuracy_metrics[dataset, \"MPE\"], 3),\n          MAPE = round(accuracy_metrics[dataset, \"MAPE\"], 3),\n          MASE = round(accuracy_metrics[dataset, \"MASE\"], 3),\n          ACF1 = round(accuracy_metrics[dataset, \"ACF1\"], 3),\n          Theil_U = ifelse(\"Theil's U\" %in% colnames(accuracy_metrics), round(accuracy_metrics[dataset, \"Theil's U\"], 3), NA)\n        )\n        results_table <- rbind(results_table, row)\n      }\n    }\n  }\n}\nfiltered_results <- results_table[results_table$Dataset == \"Training set\", ]\nknitr::kable(filtered_results, format = \"html\", caption = \"Training Set Forecast Accuracy\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n<caption>Training Set Forecast Accuracy</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> Sub_Category </th>\n   <th style=\"text-align:left;\"> Method </th>\n   <th style=\"text-align:left;\"> Dataset </th>\n   <th style=\"text-align:right;\"> ME </th>\n   <th style=\"text-align:right;\"> RMSE </th>\n   <th style=\"text-align:right;\"> MAE </th>\n   <th style=\"text-align:right;\"> MPE </th>\n   <th style=\"text-align:right;\"> MAPE </th>\n   <th style=\"text-align:right;\"> MASE </th>\n   <th style=\"text-align:right;\"> ACF1 </th>\n   <th style=\"text-align:right;\"> Theil_U </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:left;\"> Binders </td>\n   <td style=\"text-align:left;\"> ARIMA </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 0.771 </td>\n   <td style=\"text-align:right;\"> 4.643 </td>\n   <td style=\"text-align:right;\"> 2.982 </td>\n   <td style=\"text-align:right;\"> 0.687 </td>\n   <td style=\"text-align:right;\"> 12.912 </td>\n   <td style=\"text-align:right;\"> 0.485 </td>\n   <td style=\"text-align:right;\"> 0.044 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:left;\"> Binders </td>\n   <td style=\"text-align:left;\"> HoltWinters </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 0.867 </td>\n   <td style=\"text-align:right;\"> 5.215 </td>\n   <td style=\"text-align:right;\"> 3.790 </td>\n   <td style=\"text-align:right;\"> -0.404 </td>\n   <td style=\"text-align:right;\"> 15.365 </td>\n   <td style=\"text-align:right;\"> 0.617 </td>\n   <td style=\"text-align:right;\"> -0.389 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:left;\"> Binders </td>\n   <td style=\"text-align:left;\"> ETS </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 0.743 </td>\n   <td style=\"text-align:right;\"> 4.713 </td>\n   <td style=\"text-align:right;\"> 3.656 </td>\n   <td style=\"text-align:right;\"> 1.359 </td>\n   <td style=\"text-align:right;\"> 15.417 </td>\n   <td style=\"text-align:right;\"> 0.595 </td>\n   <td style=\"text-align:right;\"> -0.223 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:left;\"> Paper </td>\n   <td style=\"text-align:left;\"> ARIMA </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 1.117 </td>\n   <td style=\"text-align:right;\"> 6.309 </td>\n   <td style=\"text-align:right;\"> 3.828 </td>\n   <td style=\"text-align:right;\"> 1.702 </td>\n   <td style=\"text-align:right;\"> 14.322 </td>\n   <td style=\"text-align:right;\"> 0.547 </td>\n   <td style=\"text-align:right;\"> -0.007 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:left;\"> Paper </td>\n   <td style=\"text-align:left;\"> HoltWinters </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 1.510 </td>\n   <td style=\"text-align:right;\"> 7.280 </td>\n   <td style=\"text-align:right;\"> 4.855 </td>\n   <td style=\"text-align:right;\"> 3.325 </td>\n   <td style=\"text-align:right;\"> 16.413 </td>\n   <td style=\"text-align:right;\"> 0.694 </td>\n   <td style=\"text-align:right;\"> -0.027 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 11 </td>\n   <td style=\"text-align:left;\"> Paper </td>\n   <td style=\"text-align:left;\"> ETS </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 0.609 </td>\n   <td style=\"text-align:right;\"> 6.205 </td>\n   <td style=\"text-align:right;\"> 4.475 </td>\n   <td style=\"text-align:right;\"> -1.662 </td>\n   <td style=\"text-align:right;\"> 18.732 </td>\n   <td style=\"text-align:right;\"> 0.639 </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 13 </td>\n   <td style=\"text-align:left;\"> Furnishings </td>\n   <td style=\"text-align:left;\"> ARIMA </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n   <td style=\"text-align:right;\"> 3.874 </td>\n   <td style=\"text-align:right;\"> 2.568 </td>\n   <td style=\"text-align:right;\"> -6.625 </td>\n   <td style=\"text-align:right;\"> 20.210 </td>\n   <td style=\"text-align:right;\"> 0.556 </td>\n   <td style=\"text-align:right;\"> -0.202 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 15 </td>\n   <td style=\"text-align:left;\"> Furnishings </td>\n   <td style=\"text-align:left;\"> HoltWinters </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 0.914 </td>\n   <td style=\"text-align:right;\"> 4.165 </td>\n   <td style=\"text-align:right;\"> 3.475 </td>\n   <td style=\"text-align:right;\"> 7.490 </td>\n   <td style=\"text-align:right;\"> 24.756 </td>\n   <td style=\"text-align:right;\"> 0.752 </td>\n   <td style=\"text-align:right;\"> -0.433 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 17 </td>\n   <td style=\"text-align:left;\"> Furnishings </td>\n   <td style=\"text-align:left;\"> ETS </td>\n   <td style=\"text-align:left;\"> Training set </td>\n   <td style=\"text-align:right;\"> 0.737 </td>\n   <td style=\"text-align:right;\"> 3.467 </td>\n   <td style=\"text-align:right;\"> 2.852 </td>\n   <td style=\"text-align:right;\"> 0.430 </td>\n   <td style=\"text-align:right;\"> 20.852 </td>\n   <td style=\"text-align:right;\"> 0.617 </td>\n   <td style=\"text-align:right;\"> -0.209 </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n\n\n\n\nAs we can see on the forecasting results ARIMA performed well for binders. We can state this because of the lowest RMSE. \n\nFor the subcategory furnishings we can see that the ETS forecasting method is the most stable across the training and testing phase. \n\nFor the last subcategory and product paper the ETS model is again the most consistent, comparing the statistics for training and test set. The high variability in the test data leads to larger forecasting errors in all the 3 models.\n\nConcerning the residual diagnostics, the checks show no real autocorrelation for ARIMA models. Which indicates a good fitting forecast. \n\n### Conclusion (4a)\n\nThe most effective model is not the same in all the subcategories. Each model was validated based on its ability to capture seasonality and trend. ARIMA performed better for Binders, while ETS performed better for Furnishings and Paper. \n\n### Clustering Subcategories and forecasting (4b)\n\nSteps Taken:\n\n- Trend strength, random variation and seasonal strength were calculated for the subcategory using the time series we have.\n\n\nClustering:\n\nThe clustering method used is the hierarchical clustering method. To group subcategories into three different clusters based on features which are normalized. The hierarchical clustering gave the following results:\n\n- Cluster 1: Stronger seasonality\n\n- Cluster 2: moderate trend and seasonality\n\n- Cluster 3: Lower trend and seasonal strength\n\n\nFor each different cluster we also used the models introduced in 4A (ARIMA, Holt-Winters, ETS). These results where all aggregated at the level of each cluster so we can assess mean RMSE and MAPE for each different model.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nfiltered_results <- results_table[results_table$Dataset == \"Test set\", ]\nknitr::kable(filtered_results, format = \"html\", caption = \"Forecast Accuracy Results\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n<caption>Forecast Accuracy Results</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:left;\"> Sub_Category </th>\n   <th style=\"text-align:left;\"> Method </th>\n   <th style=\"text-align:left;\"> Dataset </th>\n   <th style=\"text-align:right;\"> ME </th>\n   <th style=\"text-align:right;\"> RMSE </th>\n   <th style=\"text-align:right;\"> MAE </th>\n   <th style=\"text-align:right;\"> MPE </th>\n   <th style=\"text-align:right;\"> MAPE </th>\n   <th style=\"text-align:right;\"> MASE </th>\n   <th style=\"text-align:right;\"> ACF1 </th>\n   <th style=\"text-align:right;\"> Theil_U </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:left;\"> Binders </td>\n   <td style=\"text-align:left;\"> ARIMA </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> 5.941 </td>\n   <td style=\"text-align:right;\"> 10.784 </td>\n   <td style=\"text-align:right;\"> 7.616 </td>\n   <td style=\"text-align:right;\"> 10.368 </td>\n   <td style=\"text-align:right;\"> 17.329 </td>\n   <td style=\"text-align:right;\"> 1.240 </td>\n   <td style=\"text-align:right;\"> 0.049 </td>\n   <td style=\"text-align:right;\"> 0.357 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:left;\"> Binders </td>\n   <td style=\"text-align:left;\"> HoltWinters </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> 2.247 </td>\n   <td style=\"text-align:right;\"> 8.712 </td>\n   <td style=\"text-align:right;\"> 6.243 </td>\n   <td style=\"text-align:right;\"> 0.160 </td>\n   <td style=\"text-align:right;\"> 16.022 </td>\n   <td style=\"text-align:right;\"> 1.016 </td>\n   <td style=\"text-align:right;\"> -0.002 </td>\n   <td style=\"text-align:right;\"> 0.278 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:left;\"> Binders </td>\n   <td style=\"text-align:left;\"> ETS </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> 7.440 </td>\n   <td style=\"text-align:right;\"> 12.216 </td>\n   <td style=\"text-align:right;\"> 8.825 </td>\n   <td style=\"text-align:right;\"> 10.667 </td>\n   <td style=\"text-align:right;\"> 20.936 </td>\n   <td style=\"text-align:right;\"> 1.437 </td>\n   <td style=\"text-align:right;\"> 0.061 </td>\n   <td style=\"text-align:right;\"> 0.377 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 8 </td>\n   <td style=\"text-align:left;\"> Paper </td>\n   <td style=\"text-align:left;\"> ARIMA </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> -9.014 </td>\n   <td style=\"text-align:right;\"> 12.231 </td>\n   <td style=\"text-align:right;\"> 10.376 </td>\n   <td style=\"text-align:right;\"> -30.104 </td>\n   <td style=\"text-align:right;\"> 31.895 </td>\n   <td style=\"text-align:right;\"> 1.482 </td>\n   <td style=\"text-align:right;\"> 0.109 </td>\n   <td style=\"text-align:right;\"> 0.698 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:left;\"> Paper </td>\n   <td style=\"text-align:left;\"> HoltWinters </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> -12.037 </td>\n   <td style=\"text-align:right;\"> 14.481 </td>\n   <td style=\"text-align:right;\"> 13.347 </td>\n   <td style=\"text-align:right;\"> -39.792 </td>\n   <td style=\"text-align:right;\"> 41.516 </td>\n   <td style=\"text-align:right;\"> 1.907 </td>\n   <td style=\"text-align:right;\"> 0.100 </td>\n   <td style=\"text-align:right;\"> 0.845 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 12 </td>\n   <td style=\"text-align:left;\"> Paper </td>\n   <td style=\"text-align:left;\"> ETS </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> 0.085 </td>\n   <td style=\"text-align:right;\"> 11.304 </td>\n   <td style=\"text-align:right;\"> 8.247 </td>\n   <td style=\"text-align:right;\"> -0.085 </td>\n   <td style=\"text-align:right;\"> 20.476 </td>\n   <td style=\"text-align:right;\"> 1.178 </td>\n   <td style=\"text-align:right;\"> 0.342 </td>\n   <td style=\"text-align:right;\"> 0.583 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 14 </td>\n   <td style=\"text-align:left;\"> Furnishings </td>\n   <td style=\"text-align:left;\"> ARIMA </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> 3.952 </td>\n   <td style=\"text-align:right;\"> 7.783 </td>\n   <td style=\"text-align:right;\"> 6.238 </td>\n   <td style=\"text-align:right;\"> 10.720 </td>\n   <td style=\"text-align:right;\"> 22.753 </td>\n   <td style=\"text-align:right;\"> 1.351 </td>\n   <td style=\"text-align:right;\"> -0.036 </td>\n   <td style=\"text-align:right;\"> 0.610 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 16 </td>\n   <td style=\"text-align:left;\"> Furnishings </td>\n   <td style=\"text-align:left;\"> HoltWinters </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> 3.637 </td>\n   <td style=\"text-align:right;\"> 7.201 </td>\n   <td style=\"text-align:right;\"> 5.673 </td>\n   <td style=\"text-align:right;\"> 9.724 </td>\n   <td style=\"text-align:right;\"> 20.501 </td>\n   <td style=\"text-align:right;\"> 1.228 </td>\n   <td style=\"text-align:right;\"> 0.018 </td>\n   <td style=\"text-align:right;\"> 0.569 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 18 </td>\n   <td style=\"text-align:left;\"> Furnishings </td>\n   <td style=\"text-align:left;\"> ETS </td>\n   <td style=\"text-align:left;\"> Test set </td>\n   <td style=\"text-align:right;\"> 6.097 </td>\n   <td style=\"text-align:right;\"> 8.354 </td>\n   <td style=\"text-align:right;\"> 6.691 </td>\n   <td style=\"text-align:right;\"> 20.728 </td>\n   <td style=\"text-align:right;\"> 23.553 </td>\n   <td style=\"text-align:right;\"> 1.449 </td>\n   <td style=\"text-align:right;\"> 0.373 </td>\n   <td style=\"text-align:right;\"> 0.746 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntop_3_subcategories <- top_categories$Sub_Category[1:3]\nkpss_results <- data.frame(\n  Sub_Category = character(),\n  KPSS_Statistic = numeric(),\n  P_Value = numeric(),\n  Null_Hypothesis = character(),\n  stringsAsFactors = FALSE\n)\n\n# Perform KPSS Test for each subcategory\nfor (subcategory in top_3_subcategories) {\n  if (subcategory %in% names(ts_list)) {\n    ts_current <- ts_list[[subcategory]]\n    test_result <- kpss.test(ts_current)\n    \n    kpss_results <- kpss_results %>%\n      add_row(\n        Sub_Category = subcategory,\n        KPSS_Statistic = test_result$statistic,\n        P_Value = test_result$p.value,\n        Null_Hypothesis = ifelse(test_result$p.value < 0.05, \n                                 \"Rejected (Non-Stationary)\", \n                                 \"Not Rejected (Stationary)\")\n      )\n  } else {\n    cat(\"\\nSub-Category not found in ts_list:\", subcategory, \"\\n\")\n  }\n}\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning in kpss.test(ts_current): p-value smaller than printed p-value\nWarning in kpss.test(ts_current): p-value smaller than printed p-value\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Print nicely formattted table\nkable(kpss_results, caption = \"KPSS Test Results for Top 3 Subcategories\", digits = 3)\n```\n\n::: {.cell-output-display}\n\n\nTable: KPSS Test Results for Top 3 Subcategories\n\n|Sub_Category | KPSS_Statistic| P_Value|Null_Hypothesis           |\n|:------------|--------------:|-------:|:-------------------------|\n|Binders      |          0.785|    0.01|Rejected (Non-Stationary) |\n|Paper        |          0.738|    0.01|Rejected (Non-Stationary) |\n|Furnishings  |          0.764|    0.01|Rejected (Non-Stationary) |\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\noptions(warn = -1)\n# # Step 6: Visualization of Forecasts\n# for (subcategory in names(forecast_results)) {\n#   plot(forecast_results[[subcategory]]$ARIMA$Forecast, main = paste(\"ARIMA Forecast for\", subcategory))\n#   lines(test_ts, col = \"red\", lty = 2)\n# \n#   plot(forecast_results[[subcategory]]$HoltWinters$Forecast, main = paste(\"Holt-Winters Forecast for\", subcategory))\n#   lines(test_ts, col = \"red\", lty = 2)\n# \n#   plot(forecast_results[[subcategory]]$ETS$Forecast, main = paste(\"ETS Forecast for\", subcategory))\n#   lines(test_ts, col = \"red\", lty = 2)\n# }\n\n#more stationary tests\n# Perform KPSS Test for the top 3 subcategories\n# top_3_subcategories <- top_categories$Sub_Category[0:3]\n# \n# for (subcategory in top_3_subcategories) {\n#   if (subcategory %in% names(ts_list)) {\n#     ts_current <- ts_list[[subcategory]]\n#     cat(\"\\nKPSS Test for Sub-Category:\", subcategory, \"\\n\")\n#     print(kpss.test(ts_current))\n#   } else {\n#     cat(\"\\nSub-Category not found in ts_list:\", subcategory, \"\\n\")\n#   }\n# }\n\n#Because the all the 3 subcategory are non stationary because of a P value which is <=0.05 we need to use differencing\n# Apply differencing to each of the top 3 subcategories\ndifferenced_series <- list()\n\nfor (subcategory in top_3_subcategories) {\n  if (subcategory %in% names(ts_list)) {\n    ts_current <- ts_list[[subcategory]]  # Get the time series for the subcategory\n    ts_diff <- diff(ts_current, differences = 1)  # Apply first-order differencing\n    differenced_series[[subcategory]] <- ts_diff  # Store the differenced series\n\n    # Recheck stationarity with KPSS test\n    #cat(\"\\nKPSS Test for Differenced Sub-Category:\", subcategory, \"\\n\")\n    print(kpss.test(ts_diff))\n  } else {\n    #cat(\"\\nSub-Category not found in ts_list:\", subcategory, \"\\n\")\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  ts_diff\nKPSS Level = 0.10182, Truncation lag parameter = 3, p-value = 0.1\n\n\n\tKPSS Test for Level Stationarity\n\ndata:  ts_diff\nKPSS Level = 0.061982, Truncation lag parameter = 3, p-value = 0.1\n\n\n\tKPSS Test for Level Stationarity\n\ndata:  ts_diff\nKPSS Level = 0.098438, Truncation lag parameter = 3, p-value = 0.1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Time differenced plots\n# # Now P value is larger then 0.05 so we have stationary data\n# # Plot the differenced series for each subcategory\n# for (subcategory in top_3_subcategories) {\n#   if (subcategory %in% names(differenced_series)) {\n#     ts_diff <- differenced_series[[subcategory]]\n#     cat(\"\\nPlotting Differenced Series for Sub-Category:\", subcategory, \"\\n\")\n#     plot(ts_diff, main = paste(\"Differenced Series for Sub-Category:\", subcategory),\n#          ylab = \"Differenced Values\", xlab = \"Time\")\n#   }\n# }\n\n# Combine differenced series plots for all top subcategories\ncombined_diff_plot <- function(differenced_series, top_3_subcategories) {\n  plot(NULL, xlim = range(time(differenced_series[[top_3_subcategories[1]]])), \n       ylim = range(sapply(differenced_series[top_3_subcategories], range, na.rm = TRUE)),\n       xlab = \"Time\", ylab = \"Differenced Values\",\n       main = \"Differenced Series for Top Subcategories\")\n  colors <- c(\"blue\", \"green\", \"purple\")\n  for (i in seq_along(top_3_subcategories)) {\n    subcategory <- top_3_subcategories[i]\n    if (subcategory %in% names(differenced_series)) {\n      ts_diff <- differenced_series[[subcategory]]\n      lines(ts_diff, col = colors[i], lwd = 2, lty = i)\n    }\n  }\n  legend(\"topright\", legend = top_3_subcategories, \n         col = colors, lty = 1:length(top_3_subcategories), lwd = 2)\n}\ncombined_diff_plot(differenced_series, top_3_subcategories)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/results3-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#NEW FORECASTING FOR 4A with stationary data\n# Step 4: Apply forecasting methods to the differenced top 3 sub-categories\nforecast_results <- list()  # Store results\n\nfor (subcategory in names(differenced_series)) {\n  ts_current <- differenced_series[[subcategory]]\n\n  train_size <- floor(0.7 * length(ts_current))\n  train_ts <- window(ts_current, end = c(2014 + (train_size - 1) %/% 12, (train_size - 1) %% 12 + 1))\n  test_ts <- window(ts_current, start = c(2014 + train_size %/% 12, train_size %% 12 + 1))\n\n  arima_model <- auto.arima(train_ts)\n  arima_forecast <- forecast(arima_model, h = length(test_ts))\n  arima_accuracy <- accuracy(arima_forecast, test_ts)\n\n  hw_model <- HoltWinters(train_ts)\n  hw_forecast <- forecast(hw_model, h = length(test_ts))\n  hw_accuracy <- accuracy(hw_forecast, test_ts)\n\n  ets_model <- ets(train_ts)\n  ets_forecast <- forecast(ets_model, h = length(test_ts))\n  ets_accuracy <- accuracy(ets_forecast, test_ts)\n\n  forecast_results[[subcategory]] <- list(\n    ARIMA = list(Model = arima_model, Forecast = arima_forecast, Accuracy = arima_accuracy),\n    HoltWinters = list(Model = hw_model, Forecast = hw_forecast, Accuracy = hw_accuracy),\n    ETS = list(Model = ets_model, Forecast = ets_forecast, Accuracy = ets_accuracy)\n  )\n}\n\n# # Step 5: Print results\n# for (subcategory in names(forecast_results)) {\n#   cat(\"\\n\\nResults for Sub_Category:\", subcategory, \"\\n\")\n# \n#   cat(\"\\nARIMA Accuracy:\\n\")\n#   print(forecast_results[[subcategory]]$ARIMA$Accuracy)\n# \n#   cat(\"\\nHolt-Winters Accuracy:\\n\")\n#   print(forecast_results[[subcategory]]$HoltWinters$Accuracy)\n# \n#   cat(\"\\nETS Accuracy:\\n\")\n#   print(forecast_results[[subcategory]]$ETS$Accuracy)\n# }\n\n# # Step 6: Visualization of Forecasts\n# for (subcategory in names(forecast_results)) {\n#   plot(forecast_results[[subcategory]]$ARIMA$Forecast,\n#        main = paste(\"ARIMA Forecast for\", subcategory),\n#        ylab = \"Differenced Values\", xlab = \"Time\")\n#   lines(test_ts, col = \"red\", lty = 2)\n# \n#   plot(forecast_results[[subcategory]]$HoltWinters$Forecast,\n#        main = paste(\"Holt-Winters Forecast for\", subcategory),\n#        ylab = \"Differenced Values\", xlab = \"Time\")\n#   lines(test_ts, col = \"red\", lty = 2)\n# \n#   plot(forecast_results[[subcategory]]$ETS$Forecast,\n#        main = paste(\"ETS Forecast for\", subcategory),\n#        ylab = \"Differenced Values\", xlab = \"Time\")\n#   lines(test_ts, col = \"red\", lty = 2)\n# }\n\n# Lets plot the results\nfor (subcategory in names(forecast_results)) {\n  ts_current <- ts_list[[subcategory]]\n  train_size <- floor(0.7 * length(ts_current))\n  test_ts <- window(ts_current, start = c(2014 + train_size %/% 12, train_size %% 12 + 1))\n  arima_forecast <- forecast_results[[subcategory]]$ARIMA$Forecast\n  hw_forecast <- forecast_results[[subcategory]]$HoltWinters$Forecast\n  ets_forecast <- forecast_results[[subcategory]]$ETS$Forecast\n  \n  # Combined plot\n  plot(arima_forecast$mean, col = \"blue\", lwd = 2, \n       ylim = range(c(arima_forecast$mean, hw_forecast$mean, ets_forecast$mean, test_ts)),\n       main = paste(\"Combined Forecasts for\", subcategory, \"before differencing\"),\n       xlab = \"Time\", ylab = \"Forecasted Values\")\n  lines(test_ts, col = \"red\", lty = 2, lwd = 2)\n  lines(hw_forecast$mean, col = \"green\", lwd = 2)\n  lines(ets_forecast$mean, col = \"purple\", lwd = 2)\n  legend(\"topleft\", legend = c(\"ARIMA\", \"Holt-Winters\", \"ETS\", \"Test Data\"),\n         col = c(\"blue\", \"green\", \"purple\", \"red\"), lty = c(1, 1, 1, 2), lwd = 2)\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/Results4-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/Results4-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/Results4-3.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# final KPSS test\n\n# Perform KPSS Test for the differenced series in the top 3 subcategories\nfor (subcategory in top_3_subcategories) {\n  if (subcategory %in% names(differenced_series)) {\n    ts_current <- differenced_series[[subcategory]]  # Get the differenced series\n    cat(\"\\nKPSS Test for Differenced Sub-Category:\", subcategory, \"\\n\")\n    print(kpss.test(ts_current))\n  } else {\n    cat(\"\\nSub-Category not found in differenced_series:\", subcategory, \"\\n\")\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nKPSS Test for Differenced Sub-Category: Binders \n\n\tKPSS Test for Level Stationarity\n\ndata:  ts_current\nKPSS Level = 0.10182, Truncation lag parameter = 3, p-value = 0.1\n\n\nKPSS Test for Differenced Sub-Category: Paper \n\n\tKPSS Test for Level Stationarity\n\ndata:  ts_current\nKPSS Level = 0.061982, Truncation lag parameter = 3, p-value = 0.1\n\n\nKPSS Test for Differenced Sub-Category: Furnishings \n\n\tKPSS Test for Level Stationarity\n\ndata:  ts_current\nKPSS Level = 0.098438, Truncation lag parameter = 3, p-value = 0.1\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# now they are all 0.1\n```\n:::\n\n\n\n\n\n\n\n### Clustering (4b)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# 4B\n# 4B: Group Products into Clusters and Apply Forecasting Techniques\ntime_series_features <- data.frame()\n\nfor (subcategory in names(ts_list)) {\n  ts_current <- ts_list[[subcategory]]\n\n  # Decompose the time series to extract features\n  decomposition <- decompose(ts_current)\n  trend_strength <- var(decomposition$trend, na.rm = TRUE) / var(ts_current, na.rm = TRUE)\n  seasonal_strength <- var(decomposition$seasonal, na.rm = TRUE) / var(ts_current, na.rm = TRUE)\n  random_strength <- var(decomposition$random, na.rm = TRUE) / var(ts_current, na.rm = TRUE)\n\n  # Store extracted features\n  time_series_features <- rbind(time_series_features,\n                                data.frame(SubCategory = subcategory,\n                                           TrendStrength = trend_strength,\n                                           SeasonalStrength = seasonal_strength,\n                                           RandomStrength = random_strength))\n}\n\n# Step 2: Normalize the Features for Clustering\ntime_series_features_scaled <- time_series_features %>%\n  select(-SubCategory) %>%\n  scale()\n\n# verify rows\n# nrow(time_series_features_scaled)\n\n# Step 3: Perform K-Means Clustering\n# Determine the number of clusters dynamically\nk <- min(3, nrow(time_series_features_scaled))  # Set k to the smaller of 3 or the number of rows\n# Hierarchical Clustering\ndistance_matrix <- dist(time_series_features_scaled)  # Calculate distance matrix\nhc <- hclust(distance_matrix)  # Perform hierarchical clustering\ntime_series_features$Cluster <- cutree(hc, k = k)  # Cut tree into 'k' clusters\n# Add cluster information to the original data\ntime_series_features$Cluster <- cutree(hc, k = k)\n\n# Step 4: Apply Forecasting Techniques to Each Cluster\nforecast_results_by_cluster <- list()\n\nfor (cluster_id in unique(time_series_features$Cluster)) {\n  # Get subcategories in the current cluster\n  subcategories_in_cluster <- time_series_features$SubCategory[time_series_features$Cluster == cluster_id]\n\n  # Initialize storage for cluster results\n  cluster_forecast_results <- list()\n\n  for (subcategory in subcategories_in_cluster) {\n    if (subcategory %in% names(ts_list)) {\n      ts_current <- ts_list[[subcategory]]  # Access the time series\n\n      # Split the data into training and validation sets (70% training, 30% testing)\n      train_size <- floor(0.7 * length(ts_current))\n      train_ts <- window(ts_current, end = c(2014 + (train_size - 1) %/% 12, (train_size - 1) %% 12 + 1))\n      test_ts <- window(ts_current, start = c(2014 + train_size %/% 12, train_size %% 12 + 1))\n\n      # 1. ARIMA\n      arima_model <- auto.arima(train_ts)\n      arima_forecast <- forecast(arima_model, h = length(test_ts))\n      arima_accuracy <- accuracy(arima_forecast, test_ts)\n\n      # 2. Holt-Winters\n      hw_model <- HoltWinters(train_ts)\n      hw_forecast <- forecast(hw_model, h = length(test_ts))\n      hw_accuracy <- accuracy(hw_forecast, test_ts)\n\n      # 3. ETS\n      ets_model <- ets(train_ts)\n      ets_forecast <- forecast(ets_model, h = length(test_ts))\n      ets_accuracy <- accuracy(ets_forecast, test_ts)\n\n      # Store results for the subcategory\n      cluster_forecast_results[[subcategory]] <- list(\n        ARIMA = list(Model = arima_model, Forecast = arima_forecast, Accuracy = arima_accuracy),\n        HoltWinters = list(Model = hw_model, Forecast = hw_forecast, Accuracy = hw_accuracy),\n        ETS = list(Model = ets_model, Forecast = ets_forecast, Accuracy = ets_accuracy)\n      )\n    } else {\n      cat(\"\\nSub-Category not found in ts_list:\", subcategory, \"\\n\")\n    }\n  }\n\n  # Store results for the cluster\n  forecast_results_by_cluster[[paste0(\"Cluster_\", cluster_id)]] <- cluster_forecast_results\n}\n\n# Step 5: Print Forecasting Accuracy for Each Cluster\nfor (cluster_id in names(forecast_results_by_cluster)) {\n  cat(\"\\n\\nResults for\", cluster_id, \"\\n\")\n  cluster_results <- forecast_results_by_cluster[[cluster_id]]\n\n  for (subcategory in names(cluster_results)) {\n    cat(\"\\nSub-Category:\", subcategory, \"\\n\")\n\n    cat(\"\\nARIMA Accuracy:\\n\")\n    print(cluster_results[[subcategory]]$ARIMA$Accuracy)\n\n    cat(\"\\nHolt-Winters Accuracy:\\n\")\n    print(cluster_results[[subcategory]]$HoltWinters$Accuracy)\n\n    cat(\"\\nETS Accuracy:\\n\")\n    print(cluster_results[[subcategory]]$ETS$Accuracy)\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nResults for Cluster_1 \n\nSub-Category: Binders \n\nARIMA Accuracy:\n                    ME      RMSE      MAE        MPE     MAPE      MASE\nTraining set 0.7706014  4.643476 2.982256  0.6865304 12.91204 0.4854835\nTest set     5.9407398 10.783528 7.616473 10.3681817 17.32927 1.2398909\n                   ACF1 Theil's U\nTraining set 0.04429472        NA\nTest set     0.04929320 0.3573866\n\nHolt-Winters Accuracy:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set 0.8668058 5.215491 3.789990 -0.4040374 15.36545 0.6169751\nTest set     2.2473496 8.712049 6.243226  0.1597635 16.02219 1.0163391\n                     ACF1 Theil's U\nTraining set -0.389045966        NA\nTest set     -0.001830843 0.2777843\n\nETS Accuracy:\n                   ME      RMSE      MAE       MPE     MAPE      MASE\nTraining set 0.743354  4.712561 3.656409  1.358692 15.41708 0.5952293\nTest set     7.439784 12.216161 8.825094 10.667088 20.93561 1.4366433\n                   ACF1 Theil's U\nTraining set -0.2225537        NA\nTest set      0.0608554 0.3767484\n\n\nResults for Cluster_2 \n\nSub-Category: Paper \n\nARIMA Accuracy:\n                    ME      RMSE       MAE        MPE     MAPE      MASE\nTraining set  1.117384  6.309464  3.827714   1.702165 14.32157 0.5468163\nTest set     -9.014128 12.230774 10.375521 -30.103886 31.89519 1.4822173\n                     ACF1 Theil's U\nTraining set -0.007064333        NA\nTest set      0.108516273 0.6984566\n\nHolt-Winters Accuracy:\n                     ME     RMSE       MAE        MPE     MAPE      MASE\nTraining set   1.509544  7.27986  4.854547   3.325281 16.41309 0.6935067\nTest set     -12.036865 14.48061 13.347292 -39.791842 41.51609 1.9067560\n                    ACF1 Theil's U\nTraining set -0.02710216        NA\nTest set      0.10006713  0.845232\n\nETS Accuracy:\n                     ME      RMSE      MAE         MPE     MAPE      MASE\nTraining set 0.60941117  6.204628 4.474990 -1.66197953 18.73240 0.6392842\nTest set     0.08500424 11.304488 8.247017 -0.08462612 20.47598 1.1781453\n                    ACF1 Theil's U\nTraining set 0.005205508        NA\nTest set     0.341519997  0.582549\n\n\nResults for Cluster_3 \n\nSub-Category: Furnishings \n\nARIMA Accuracy:\n                    ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 0.0050974 3.873555 2.567868 -6.624673 20.20958 0.5559302\nTest set     3.9523810 7.782677 6.238095 10.720079 22.75340 1.3505155\n                    ACF1 Theil's U\nTraining set -0.20160077        NA\nTest set     -0.03570035 0.6102339\n\nHolt-Winters Accuracy:\n                    ME     RMSE      MAE      MPE     MAPE      MASE\nTraining set 0.9137655 4.164677 3.475419 7.490317 24.75583 0.7524103\nTest set     3.6371987 7.200985 5.673333 9.724318 20.50134 1.2282474\n                    ACF1 Theil's U\nTraining set -0.43317305        NA\nTest set      0.01804785 0.5689788\n\nETS Accuracy:\n                    ME     RMSE      MAE        MPE     MAPE     MASE\nTraining set 0.7370579 3.466690 2.851745  0.4301648 20.85220 0.617388\nTest set     6.0973038 8.354163 6.690832 20.7276401 23.55317 1.448531\n                   ACF1 Theil's U\nTraining set -0.2087083        NA\nTest set      0.3729315 0.7455977\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n## Step 6: Visualize the Clusters\nlibrary(ggplot2)\n\nggplot(time_series_features, aes(x = TrendStrength, y = SeasonalStrength, color = as.factor(Cluster))) +\n  geom_point(size = 3) +\n  labs(title = \"Clusters of Subcategories Based on Time-Series Features\",\n       x = \"Trend Strength\", y = \"Seasonal Strength\", color = \"Cluster\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/somelable-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code .hidden}\n#\n#check\n#residual diagnostic\nfor (cluster_id in names(forecast_results_by_cluster)) {\n  cluster_results <- forecast_results_by_cluster[[cluster_id]]\n  for (subcategory in names(cluster_results)) {\n    cat(\"\\nResidual Diagnostics for Sub-Category:\", subcategory, \"\\n\")\n    checkresiduals(cluster_results[[subcategory]]$ARIMA$Model)\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResidual Diagnostics for Sub-Category: Binders \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/somelable-2.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(0,1,2)(0,1,0)[12]\nQ* = 2.6295, df = 5, p-value = 0.7569\n\nModel df: 2.   Total lags used: 7\n\n\nResidual Diagnostics for Sub-Category: Paper \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/somelable-3.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(0,1,1)(0,1,0)[12]\nQ* = 6.6676, df = 6, p-value = 0.3527\n\nModel df: 1.   Total lags used: 7\n\n\nResidual Diagnostics for Sub-Category: Furnishings \n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/somelable-4.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tLjung-Box test\n\ndata:  Residuals from ARIMA(0,0,0)(0,1,0)[12] with drift\nQ* = 9.5952, df = 7, p-value = 0.2127\n\nModel df: 0.   Total lags used: 7\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# P-value is higher then 0.1 so we have stationary data, this is good\n#cluster level metrics\ncluster_metrics <- data.frame()\nfor (cluster_id in names(forecast_results_by_cluster)) {\n  cluster_results <- forecast_results_by_cluster[[cluster_id]]\n  cluster_rmse <- sapply(cluster_results, function(x) x$ARIMA$Accuracy[\"Test set\", \"RMSE\"])\n  cluster_mape <- sapply(cluster_results, function(x) x$ARIMA$Accuracy[\"Test set\", \"MAPE\"])\n  cluster_metrics <- rbind(cluster_metrics, data.frame(Cluster = cluster_id, MeanRMSE = mean(cluster_rmse), MeanMAPE = mean(cluster_mape)))\n}\nprint(cluster_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Cluster  MeanRMSE MeanMAPE\n1 Cluster_1 10.783528 17.32927\n2 Cluster_2 12.230774 31.89519\n3 Cluster_3  7.782677 22.75340\n```\n\n\n:::\n:::\n\n\n\n\nCluster 1 (e.g., Binders): ARIMA outperformed other methods due to significant autocorrelation and trend components.\n\nCluster 2 (e.g., Furnishings): ETS was the most accurate method, effectively balancing trend and seasonality.\n\nCluster 3 (e.g., Paper): ETS also performed best, with ARIMA showing higher error rates due to variability in random components.\n\nResidual diagnostics were performed for all ARIMA models, confirming no significant autocorrelation (p > 0.05).\n\nCluster-Level Metrics based on mean RMSE and MAPE show:\n-   Cluster 1 had the lowest RMSE using ARIMA.\n-   Cluster 2 and 3 were better modeled with ETS\n\n### Conclusion (4b)\n\nClustering allows for tailored forecasting strategies. We conclude that for the given data set ARIMA is more effective for clusters with strong trends, while ETS is preferable for clusters with mixed seasonal and trend characteristics. The approach aligns with lecture notes, emphasizing the importance of adapting models based on time series characteristics.\n\n## Forecasting future values\n\n### Forecasting 3 products (5a)\n\nIn this session, we focused on evaluating different forecasting models (ARIMA, Holt-Winters, and ETS) for multiple sub-categories by analyzing their accuracy metrics, such as RMSE, MAPE, and residual diagnostics. Based on the evaluation results, we selected the best-performing model for each sub-category. We then used these models to forecast the future outcomes for each sub-category, projecting the data for the next year. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#Binders->choose ARIMA\nbinders_ts <- ts_list[[\"Binders\"]]\narima_model <- auto.arima(binders_ts)\nsummary(arima_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: binders_ts \nARIMA(1,1,1)(0,1,0)[12] \n\nCoefficients:\n          ar1      ma1\n      -0.4781  -0.4819\ns.e.   0.2324   0.2426\n\nsigma^2 = 51.18:  log likelihood = -117.97\nAIC=241.94   AICc=242.72   BIC=246.61\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE     MAPE     MASE        ACF1\nTraining set 0.864453 5.931761 4.092168 -1.363101 15.06142 0.558023 -0.03746012\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\narima_forecast <- forecast(arima_model, h = 12)\nprint(arima_forecast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Point Forecast    Lo 80     Hi 80     Lo 95     Hi 95\nJan 2018       32.48390 23.31571  41.65208 18.462370  46.50543\nFeb 2018       23.77181 14.59632  32.94731  9.739103  37.80452\nMar 2018       45.85265 35.59989  56.10541 30.172412  61.53289\nApr 2018       46.20475 35.63662  56.77287 30.042185  62.36730\nMay 2018       44.08009 32.93968  55.22051 27.042295  61.11789\nJun 2018       44.61784 33.06359  56.17210 26.947139  62.28855\nJul 2018       40.36072 28.34867  52.37277 21.989869  58.73157\nAug 2018       44.48366 32.05796  56.90937 25.480189  63.48714\nSep 2018       73.42488 60.58630  86.26346 53.789962  93.05979\nOct 2018       51.45299 38.22024  64.68573 31.215253  71.69072\nNov 2018       72.43955 58.82134  86.05775 51.612293  93.26680\nDec 2018       89.44597 75.45417 103.43777 68.047363 110.84458\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nplot(arima_forecast, main = \"ARIMA Forecast for Binders (Next 12 Months)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-21-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code .hidden}\n#Paper->choose ETS\npaper_ts <- ts_list[[\"Paper\"]]\nets_model <- ets(paper_ts)\nsummary(ets_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nETS(M,N,A) \n\nCall:\nets(y = paper_ts)\n\n  Smoothing parameters:\n    alpha = 0.3075 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 22.5954 \n    s = 17.4472 16.5763 -4.1253 15.2986 0.421 -5.102\n           -0.6145 -0.0341 -7.985 -2.6766 -15.6576 -13.5481\n\n  sigma:  0.2365\n\n     AIC     AICc      BIC \n365.1517 380.1517 393.2197 \n\nTraining set error measures:\n                   ME     RMSE      MAE     MPE     MAPE      MASE       ACF1\nTraining set 1.450303 6.386648 4.166875 1.75373 14.03399 0.5245018 0.03600045\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nets_forecast <- forecast(ets_model, h = 12)\nprint(ets_forecast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\nJan 2018       30.45588 21.22661 39.68516 16.34092 44.57085\nFeb 2018       28.34651 19.27484 37.41819 14.47258 42.22044\nMar 2018       41.32776 28.18367 54.47185 21.22561 61.42990\nApr 2018       36.01933 23.73891 48.29976 17.23804 54.80062\nMay 2018       43.97017 29.09477 58.84557 21.22021 66.72013\nJun 2018       43.39031 28.07408 58.70653 19.96616 66.81445\nJul 2018       38.90220 24.12853 53.67588 16.30782 61.49659\nAug 2018       44.42410 27.84663 61.00158 19.07104 69.77717\nSep 2018       59.30522 38.44478 80.16566 27.40193 91.20850\nOct 2018       39.87917 22.81850 56.93984 13.78712 65.97122\nNov 2018       60.58102 38.27853 82.88352 26.47230 94.68975\nDec 2018       61.45110 38.17748 84.72473 25.85717 97.04504\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nplot(ets_forecast, main = \"ETS Forecast for Paper (Next 12 Months)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-21-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code .hidden}\n#Furnishings->choose ETS\nfurnishings_ts <- ts_list[[\"Furnishings\"]]\nets_model <- ets(furnishings_ts)\nsummary(ets_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nETS(M,A,A) \n\nCall:\nets(y = furnishings_ts)\n\n  Smoothing parameters:\n    alpha = 0.0438 \n    beta  = 0.0437 \n    gamma = 2e-04 \n\n  Initial states:\n    l = 15.4275 \n    b = -0.1137 \n    s = 13.3158 15.6269 -2.2962 10.1503 -5.0017 -2.448\n           -3.4406 -1.0728 -1.1262 -4.3688 -11.689 -7.6497\n\n  sigma:  0.2527\n\n     AIC     AICc      BIC \n338.8888 359.2888 370.6992 \n\nTraining set error measures:\n                    ME     RMSE      MAE        MPE    MAPE      MASE\nTraining set 0.6402485 3.793384 2.884208 -0.8302416 16.2441 0.5352139\n                   ACF1\nTraining set 0.04613441\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nets_forecast <- forecast(ets_model, h = 12)\nprint(ets_forecast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Point Forecast    Lo 80    Hi 80     Lo 95    Hi 95\nJan 2018       21.37433 14.45350 28.29515 10.789837 31.95882\nFeb 2018       18.56644 12.52244 24.61044  9.322944 27.80994\nMar 2018       27.11574 18.26943 35.96205 13.586481 40.64500\nApr 2018       31.58782 21.22159 41.95404 15.734048 47.44158\nMay 2018       32.87189 21.95559 43.78819 16.176845 49.56693\nJun 2018       31.73384 20.95052 42.51717 15.242170 48.22551\nJul 2018       33.95710 22.18459 45.72960 15.952604 51.96159\nAug 2018       32.63192 20.83816 44.42569 14.594916 50.66893\nSep 2018       49.01546 31.92061 66.11032 22.871140 75.15979\nOct 2018       37.79884 23.38308 52.21460 15.751844 59.84584\nNov 2018       56.95159 36.44698 77.45621 25.592490 88.31070\nDec 2018       55.87232 34.96477 76.77986 23.896983 87.84765\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nplot(ets_forecast, main = \"ETS Forecast for Furnishings (Next 12 Months)\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-21-3.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n### Applying to all data (5b)\n\nIn this session, we first grouped the sub-categories into clusters based on key time-series features, including trend strength, seasonal strength, and random strength, using hierarchical clustering. Once the clusters were formed, we applied and evaluated multiple forecasting models—ARIMA, Holt-Winters, and ETS—on each sub-category within its respective cluster, comparing their accuracy metrics such as RMSE and MAPE. Based on the evaluation results, we selected the best-performing model for each sub-category and used it to forecast the future outcomes within a year, leveraging the clustering to enhance the accuracy and relevance of our predictions.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#Cluster_Binders->Holt-Winters\ncluster_id <- 1\nsubcategory <- \"Binders\"\nhw_model <- forecast_results_by_cluster[[paste0(\"Cluster_\", cluster_id)]][[subcategory]]$HoltWinters$Model\nhw_forecast <- forecast(hw_model, h = 12)\nprint(hw_forecast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Point Forecast    Lo 80    Hi 80     Lo 95    Hi 95\nOct 2016       31.26733 24.51360 38.02106 20.938398 41.59627\nNov 2016       58.57211 51.81274 65.33147 48.234553 68.90966\nDec 2016       46.52209 39.75006 53.29412 36.165163 56.87901\nJan 2017       20.60516 13.81068 27.39965 10.213895 30.99643\nFeb 2017       17.19081 10.36138 24.02023  6.746097 27.63551\nMar 2017       32.40031 25.52088 39.27975 21.879129 42.92150\nApr 2017       36.54419 29.59727 43.49111 25.919798 47.16858\nMay 2017       42.60581 35.57173 49.63990 31.848113 53.36351\nJun 2017       34.81156 27.66868 41.95444 23.887472 45.73565\nJul 2017       37.46761 30.19266 44.74256 26.341532 48.59368\nAug 2017       38.24466 30.81304 45.67627 26.878978 49.61034\nSep 2017       67.16755 59.55368 74.78141 55.523142 78.81195\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nplot(hw_forecast, main = \"Holt-Winters Forecast for Binders (Next 12 Months)\", xlab = \"Time\", ylab = \"Forecasted Values\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-22-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code .hidden}\n#Cluster_paper->ETS\ncluster_id <- 2\nsubcategory <- \"Paper\"\nets_model <- forecast_results_by_cluster[[paste0(\"Cluster_\", cluster_id)]][[subcategory]]$ETS$Model\nets_forecast <- forecast(ets_model, h = 12)\nprint(ets_forecast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Point Forecast     Lo 80    Hi 80      Lo 95     Hi 95\nOct 2016       25.88021 14.987312 36.77312  9.2209588  42.53947\nNov 2016       59.89171 33.023650 86.75978 18.8005561 100.98287\nDec 2016       66.56848 34.945434 98.19153 18.2052047 114.93176\nJan 2017       14.00226  6.995420 21.00910  3.2862229  24.71830\nFeb 2017       12.48362  5.931497 19.03574  2.4630129  22.50422\nMar 2017       29.00633 13.095755 44.91690  4.6732073  53.33945\nApr 2017       26.62997 11.410973 41.84896  3.3545236  49.90541\nMay 2017       42.52022 17.268520 67.77192  3.9010776  81.13936\nJun 2017       35.62513 13.690064 57.56019  2.0783432  69.17191\nJul 2017       25.03347  9.084935 40.98201  0.6422896  49.42466\nAug 2017       29.56385 10.109840 49.01785 -0.1884895  59.31618\nSep 2017       51.80976 16.651800 86.96771 -1.9596973 105.57921\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nplot(ets_forecast, main = \"ETS Forecast for Paper (Next 12 Months)\", xlab = \"Time\", ylab = \"Forecasted Values\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-22-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code .hidden}\n#Cluster_Furnishings->Holt-Winters\ncluster_id <- 3\nsubcategory <- \"Furnishings\"\nhw_model <- forecast_results_by_cluster[[paste0(\"Cluster_\", cluster_id)]][[subcategory]]$HoltWinters$Model\nhw_forecast <- forecast(hw_model, h = 12)\nprint(hw_forecast)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95\nOct 2016       14.89552  9.559730 20.23131  6.735134 23.05590\nNov 2016       36.06019 30.724406 41.39598 27.899811 44.22058\nDec 2016       32.74939 27.413606 38.08518 24.589010 40.90978\nJan 2017       13.37457  8.038784 18.71036  5.214189 21.53496\nFeb 2017       12.97277  7.636978 18.30855  4.812382 21.13315\nMar 2017       19.37898 14.043187 24.71476 11.218592 27.53936\nApr 2017       17.92073 12.584940 23.25652  9.760344 26.08111\nMay 2017       28.71390 23.378112 34.04969 20.553516 36.87428\nJun 2017       18.46131 13.125525 23.79710 10.300929 26.62170\nJul 2017       21.50610 16.170317 26.84189 13.345721 29.66649\nAug 2017       12.73905  7.403259 18.07484  4.578664 20.89943\nSep 2017       37.80356 32.467775 43.13935 29.643179 45.96395\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nplot(hw_forecast, main = \"Holt-Winters Forecast for Furnishings (Next 12 Months)\", xlab = \"Time\", ylab = \"Forecasted Values\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-pdf/unnamed-chunk-22-3.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n## Forecast interpretation\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# There was some missing pieces of code that I did not want to remove, but added no value either, \n\n\n# Check for missing values\nmissing_values <- colSums(is.na(data))\nprint(missing_values)  # Print missing values for reference\n# heat map\nlibrary(Amelia)\nmissmap(data, main = \"Missing Data Pattern\")\n#distribution of key variables\n#plot Quantity\nggplot(data, aes(x = Quantity)) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\") +\n  labs(title = \"Distribution of Quantity\", x = \"Quantity\", y = \"Frequency\") +\n  theme_minimal()\n#plot sales\nggplot(data, aes(x = Sales)) +\n  geom_histogram(binwidth = 50, fill = \"tomato\") +\n  labs(title = \"Distribution of Sales\", x = \"Sales\", y = \"Frequency\") +\n  theme_minimal()\n# plot profit\nggplot(data, aes(x = Profit)) +\n  geom_histogram(binwidth = 10, fill = \"purple\") +\n  labs(title = \"Distribution of Profit\", x = \"Profit\", y = \"Frequency\") +\n  theme_minimal()\n# time based trends\ndata$Order_Date <- as.Date(data$Order_Date, format = \"%Y-%m-%d\")  # Ensure date format\ntime_series <- data %>%\n  group_by(Order_Date) %>%\n  summarize(total_sales = sum(Sales), total_profit = sum(Profit), total_quantity = sum(Quantity))\n\nggplot(time_series, aes(x = Order_Date)) +\n  geom_line(aes(y = total_sales, color = \"Sales\")) +\n  geom_line(aes(y = total_profit, color = \"Profit\")) +\n  geom_line(aes(y = total_quantity, color = \"Quantity\")) +\n  labs(title = \"Sales, Profit, and Quantity Over Time\", x = \"Date\", y = \"Value\") +\n  theme_minimal() +\n  scale_color_manual(name = \"Metrics\", values = c(\"Sales\" = \"blue\", \"Profit\" = \"green\", \"Quantity\" = \"red\"))\n\n#sales by category and sub category\ncategory_sales <- data %>%\n  group_by(Category, Sub_Category) %>%\n  summarize(total_sales = sum(Sales))\n\nggplot(category_sales, aes(x = reorder(Sub_Category, -total_sales), y = total_sales, fill = Category)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Sales by Category and Sub-Category\", x = \"Sub-Category\", y = \"Total Sales\") +\n  theme_minimal() +\n  coord_flip()\n\n#Outliers detection\n#Quantity\nggplot(data, aes(x = Category, y = Quantity)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Quantity by Category\", x = \"Category\", y = \"Quantity\")\n#sales\nggplot(data, aes(x = Category, y = Sales)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Sales by Category\", x = \"Category\", y = \"Sales\")\n\n#profit\nggplot(data, aes(x = Category, y = Profit)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Profit by Category\", x = \"Category\", y = \"Profit\")\n#Geo visualization\n\nus_map <- map_data(\"state\")\nif(\"State\" %in% colnames(data)) {\n  state_sales <- data %>%\n    group_by(State) %>%\n    summarize(total_sales = sum(Sales))\n\n  # Convert state names to lowercase to match map data\n  state_sales$State <- tolower(state_sales$State)\n\n  # Merge state sales data with map data\n  state_sales_map <- merge(us_map, state_sales, by.x = \"region\", by.y = \"State\", all.x = TRUE)\n\n  # Plot sales by state\n  ggplot(state_sales_map, aes(long, lat, group = group, fill = total_sales)) +\n    geom_polygon(color = \"white\") +\n    scale_fill_continuous(low = \"lightblue\", high = \"darkblue\", na.value = \"gray90\") +\n    labs(title = \"Sales by State\", fill = \"Total Sales\") +\n    theme_void() +\n    coord_fixed(1.3)\n}\n\n# correlation matrix\nnumerical_data <- data %>% select(where(is.numeric))\n\ncor_matrix <- cor(numerical_data, use = \"complete.obs\")\n\n# Convert the correlation matrix to a long format\ncor_data <- as.data.frame(as.table(cor_matrix))\n\n# Plot the correlation matrix using ggplot2\nggplot(cor_data, aes(Var1, Var2, fill = Freq)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\",\n                       midpoint = 0, limit = c(-1, 1), space = \"Lab\",\n                       name=\"Correlation\") +\n  geom_text(aes(label = round(Freq, 2)), color = \"black\", size = 4) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1,\n                                   size = 12, hjust = 1)) +\n  coord_fixed() +\n  labs(title = \"Correlation Matrix of Key Variables\", x = \"\", y = \"\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#Aggregate sales per month\nmonthly_sales <- data %>%\n  mutate(Month = floor_date(Order_Date, \"month\")) %>%\n  group_by(Month) %>%\n  summarize(total_sales = sum(Sales))\n#Convert to time series\nsales_ts <- ts(monthly_sales$total_sales, frequency = 12, start = c(year(min(monthly_sales$Month)), month(min(monthly_sales$Month))))\n#Arima model\narima_model <- auto.arima(sales_ts)\narima_forecast <- forecast(arima_model, h = 12)\nautoplot(arima_forecast) + labs(title = \"ARIMA Forecast for Monthly Sales\")\n#Holts winter model\nhw_model <- HoltWinters(sales_ts)\nhw_forecast <- forecast(hw_model, h = 12)\nautoplot(hw_forecast) + labs(title = \"Holt-Winters Forecast for Monthly Sales\")\n# clustering for segmentation\nlibrary(cluster)\n#data clustering\nclustering_data <- data %>%\n  select(Sales, Quantity, Discount, Profit) %>%\n  na.omit()\nset.seed(123)\nkmeans_model <- kmeans(clustering_data, centers = 3)\ndata$Cluster <- as.factor(kmeans_model$cluster)\n# visualize clustering result\nggplot(data, aes(x = Sales, y = Profit, color = Cluster)) +\n  geom_point(alpha = 0.6) +\n  labs(title = \"K-Means Clustering of Sales and Profit\", x = \"Sales\", y = \"Profit\") +\n  theme_minimal()\n```\n:::",
    "supporting": [
      "index_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}