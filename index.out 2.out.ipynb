{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Chain Data Analytics"
   ],
   "id": "85c0a1ac-9d50-40aa-bbce-007d614fd88a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing and Forcasting Supermarket Sales\n",
    "\n",
    "Stan Brouwer (Vrije Universiteit)  \n",
    "Liz Chan (Master TSCM)  \n",
    "Maaike Lamberst (Supply Chain Data analysis)  \n",
    "Niek Schroor (Group 10)  \n",
    "December 5, 2024"
   ],
   "id": "849b3526-cc7a-49ca-a916-949194fa166d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "5bd31506-0b72-4bf6-9fa2-790dcf547f9e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction"
   ],
   "id": "da879eaf-acfa-4518-9b60-82eaed332469"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "4907d4ff-82b5-47d9-8daf-5c22039972ba"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyze, forecast and interpret the [Superstore sales](https://public.tableau.com/app/sample-data/sample_-_superstore.xls) provided by [Tableau](https://public.tableau.com/app/learn/sample-data) using different statistical and machine learning methods.\n",
    "\n",
    "We describe our work in the PDF version. However, we would like to recommend reading our quarto manuscript *here* as it contains the **relevant** R code in the Article Notebook.\n",
    "\n",
    "## 1 Data Pre-processing\n",
    "\n",
    "The superstore data set we selected is of high quality. Thus we do the required data pre-processing, but included the hypothetical steps we would take were our data of lower quality to communicate our understanding of the data pre-processing process.\n",
    "\n",
    "We took the following pre-processing steps:"
   ],
   "id": "d7d31d56-c042-4b60-bba3-cd7e90f2ebff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading required package: tidyverse── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.4     ✔ readr     2.1.5\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
      "✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n",
      "✔ purrr     1.0.2     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n",
      "Loading required package: readxl\n",
      "\n",
      "Loading required package: AmeliaWarning: package 'Amelia' was built under R version 4.3.3Loading required package: Rcpp\n",
      "## \n",
      "## Amelia II: Multiple Imputation\n",
      "## (Version 1.8.3, built: 2024-11-07)\n",
      "## Copyright (C) 2005-2024 James Honaker, Gary King and Matthew Blackwell\n",
      "## Refer to http://gking.harvard.edu/amelia/ for more information\n",
      "## \n",
      "Loading required package: forecastWarning: package 'forecast' was built under R version 4.3.3Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "Loading required package: tseriesWarning: package 'tseries' was built under R version 4.3.3Loading required package: plotly\n",
      "\n",
      "Attaching package: 'plotly'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    last_plot\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "The following object is masked from 'package:graphics':\n",
      "\n",
      "    layout\n",
      "\n",
      "Loading required package: knitrWarning: package 'knitr' was built under R version 4.3.3"
     ]
    }
   ],
   "source": [
    "# Clear workspace\n",
    "rm(list = ls())\n",
    "# Function to load (and install if necessary) dependencies\n",
    "install_and_load <- function(packages) {\n",
    "  install.packages(setdiff(packages, rownames(installed.packages())), dependencies = TRUE)\n",
    "  invisible(lapply(packages, require, character.only = TRUE))\n",
    "}\n",
    "install_and_load(c(\"tidyverse\", \"readxl\", \"ggplot2\", \"lubridate\", \"stats\", \"Amelia\",\"forecast\", \"tseries\", \"plotly\", \"stringr\", \"knitr\"))"
   ],
   "id": "69337c99-6b39-4ce9-a6d4-cc534cdb0f4f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Improved column names by removing whitespaces\n",
    "-   Removed the <code>Row_ID</code> column as it can be inferred by it’s index\n",
    "-   Removed all columns with a single unique value, as storing these would be [redundant](https://few.vu.nl/~molenaar/courses/StatR/chapters/B-06-raw_data.html)\n",
    "-   Ensured machine-readable date formats in yyyy-mm-dd as these usually differ per locale.\n",
    "-   Ensured proper decimal separators\n",
    "-   calculated the number of missing values (both NA and empty string ““) per column."
   ],
   "id": "08adf834-669a-4137-ac53-473ed9f3c46a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1] \"No missing values\""
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "suppressWarnings({data <- read_excel(\"data/sample_-_superstore.xls\")}) # The Postal code column is stored as 'text' but coerced to numeric, causing warnings which we suppress\n",
    "\n",
    "# Improve column names (replace \" \"with \"_\")\n",
    "colnames(data) <- str_replace_all(colnames(data), \" \", \"_\")\n",
    "\n",
    "# Remove the 'Row_ID' column as it can be inferred by it's index\n",
    "data <- subset(data, select = -`Row_ID`)\n",
    "\n",
    "# Remove all columns that have only one unique value, as storing these would be redundant\n",
    "data <- data[, sapply(data, function(col) length(unique(col)) > 1)]\n",
    "\n",
    "# Ensure a machine-readable date format as these are usually horrible in excel files\n",
    "data$Order_Date <- as.Date(data$Order_Date, format = \"%Y-%m-%d\")\n",
    "data$Ship_Date <- as.Date(data$Ship_Date, format = \"%Y-%m-%d\")\n",
    "\n",
    "# The readxl package by default uses the correct decimal separator (as opposed to base R)\n",
    "\n",
    "# Calculate the number of missing values per column.\n",
    "# The sample dates are likely in Unix time, and when these are converted to R date objects they are stored as Date objects (which are represented by 'double' datatypes). Comparing these dates to characters (empty strings) results in NA values. Thus we only check date values for NA. As Date objects are stored as doubles within R (amount of days since 1970-01-01), we can't check numeric columns for \" \" either. We thus only check character columns for \" \".\n",
    "missing_values <- sapply(data, function(col) {\n",
    "  if (inherits(col, \"Date\")) {\n",
    "    sum(is.na(col))\n",
    "  } else if (is.character(col)) {\n",
    "    sum(is.na(col) | col == \"\")\n",
    "  } else {\n",
    "    sum(is.na(col))\n",
    "  }\n",
    "})\n",
    "\n",
    "if (sum(missing_values) == 0) {\n",
    "  print(\"No missing values\")\n",
    "}"
   ],
   "id": "148d8508-c7d2-4e80-929a-2b1b6cd11f65"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also ran some descriptive statistics to check unlikely or impossible values, outliers, means, etc."
   ],
   "id": "b81e65cc-f83b-436e-b1e3-c1e79af543ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# A tibble: 5 × 19\n",
      "  Order_ID     Order_Date Ship_Date  Ship_Mode Customer_ID Customer_Name Segment\n",
      "  <chr>        <date>     <date>     <chr>     <chr>       <chr>         <chr>  \n",
      "1 CA-2016-152… 2016-11-08 2016-11-11 Second C… CG-12520    Claire Gute   Consum…\n",
      "2 CA-2016-152… 2016-11-08 2016-11-11 Second C… CG-12520    Claire Gute   Consum…\n",
      "3 CA-2016-138… 2016-06-12 2016-06-16 Second C… DV-13045    Darrin Van H… Corpor…\n",
      "4 US-2015-108… 2015-10-11 2015-10-18 Standard… SO-20335    Sean O'Donne… Consum…\n",
      "5 US-2015-108… 2015-10-11 2015-10-18 Standard… SO-20335    Sean O'Donne… Consum…\n",
      "# ℹ 12 more variables: City <chr>, State <chr>, Postal_Code <dbl>,\n",
      "#   Region <chr>, Product_ID <chr>, Category <chr>, `Sub-Category` <chr>,\n",
      "#   Product_Name <chr>, Sales <dbl>, Quantity <dbl>, Discount <dbl>,\n",
      "#   Profit <dbl>"
     ]
    }
   ],
   "source": [
    "# Select only numerical columns\n",
    "numerical_data <- data %>% select_if(is.numeric)\n",
    "\n",
    "# Apply sapply to calculate descriptive statistics for each numeric column\n",
    "descriptive_stats <- sapply(numerical_data, function(col) {\n",
    "  # Remove NA values\n",
    "  col <- na.omit(col)\n",
    "  \n",
    "  # Calculate basic statistics\n",
    "  min_val <- min(col)\n",
    "  max_val <- max(col)\n",
    "  mean_val <- mean(col)\n",
    "  median_val <- median(col)\n",
    "  \n",
    "  # 95% Confidence Interval (assuming normal distribution)\n",
    "  se <- sd(col) / sqrt(length(col))  # Standard error\n",
    "  ci_lower <- mean_val - 1.96 * se  # Lower bound of 95% CI\n",
    "  ci_upper <- mean_val + 1.96 * se  # Upper bound of 95% CI\n",
    "  \n",
    "  # Calculate outliers (using 1.5 * IQR rule)\n",
    "  Q1 <- quantile(col, 0.25)\n",
    "  Q3 <- quantile(col, 0.75)\n",
    "  IQR <- Q3 - Q1\n",
    "  outliers <- sum(col < (Q1 - 1.5 * IQR) | col > (Q3 + 1.5 * IQR))  # Number of outliers\n",
    "  \n",
    "  # Return the statistics as a named vector\n",
    "  return(c(Min = min_val, \n",
    "           Mean = mean_val, \n",
    "           Max = max_val, \n",
    "           Median = median_val, \n",
    "           `95% CI Lower` = ci_lower, \n",
    "           `95% CI Upper` = ci_upper, \n",
    "           Outliers = outliers))\n",
    "})\n",
    "head(data,5)"
   ],
   "id": "412655fd-4fc4-4406-a922-2a189b0c861e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some more processing to do, such as removing outliers. However, by doing so we impose our own assumptions on the data (possibly the outliers are actual sales?). We will visualize and qualitatively evaluate the data first, and then decide what other processing steps to take."
   ],
   "id": "f1aa39cb-136f-4f96-a52b-52a1135a912c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "# Display the first 5 rows of the data in a nice table with kable\n",
    "kable(head(data,5), caption = \"First 5 Rows of the Data\", format = \"pipe\")"
   ],
   "id": "25ab37f1-d368-4c61-b41e-481172c82c7f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Section\n",
    "\n",
    "This is a simple placeholder for the manuscript’s main document ([**knuth84?**](#ref-knuth84))."
   ],
   "id": "ca73d308-b7d2-43a9-80ad-e80854581beb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1] 2"
     ]
    }
   ],
   "source": [
    "1 + 1"
   ],
   "id": "9c2fcecf-6445-4cc8-9218-b666bcdca55b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Introduction"
   ],
   "id": "20fe86a8-1a18-436d-a6f8-4ad67175020a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eruptions <- c(1492, 1585, 1646, 1677, 1712, 1949, 1971, 2021)\n",
    "n_eruptions <- length(eruptions)"
   ],
   "id": "af4d3d8d-1d5f-40ea-b014-2334e82bd866"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "par(mar = c(3, 1, 1, 1) + 0.1)\n",
    "plot(eruptions, rep(0, n_eruptions), \n",
    "  pch = \"|\", axes = FALSE)\n",
    "axis(1)\n",
    "box()"
   ],
   "id": "cell-fig-timeline"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1] 79.83333"
     ]
    }
   ],
   "source": [
    "avg_years_between_eruptions <- mean(diff(eruptions[-n_eruptions]))\n",
    "avg_years_between_eruptions"
   ],
   "id": "74d96b0e-38ba-40e4-8a00-2874e7deed9e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on data up to and including 1971, eruptions on La Palma happen every 79.8 years on average.\n",
    "\n",
    "Studies of the magma systems feeding the volcano, such as Marrero et al. ([2019](#ref-marrero2019)), have proposed that there are two main magma reservoirs feeding the Cumbre Vieja volcano; one in the mantle (30-40km depth) which charges and in turn feeds a shallower crustal reservoir (10-20km depth).\n",
    "\n",
    "Eight eruptions have been recorded since the late 1400s (<a href=\"#fig-timeline\" class=\"quarto-xref\">Figure 1</a>).\n",
    "\n",
    "Data and methods are discussed in <a href=\"#sec-data-methods\" class=\"quarto-xref\">Section 4</a>.\n",
    "\n",
    "Let $x$ denote the number of eruptions in a year. Then, $x$ can be modeled by a Poisson distribution\n",
    "\n",
    "<span id=\"eq-poisson\">$$\n",
    "p(x) = \\frac{e^{-\\lambda} \\lambda^{x}}{x !}\n",
    " \\qquad(1)$$</span>\n",
    "\n",
    "where $\\lambda$ is the rate of eruptions per year. Using <a href=\"#eq-poisson\" class=\"quarto-xref\">Equation 1</a>, the probability of an eruption in the next $t$ years can be calculated.\n",
    "\n",
    "| Name                | Year |\n",
    "|---------------------|------|\n",
    "| Current             | 2021 |\n",
    "| Teneguía            | 1971 |\n",
    "| Nambroque           | 1949 |\n",
    "| El Charco           | 1712 |\n",
    "| Volcán San Antonio  | 1677 |\n",
    "| Volcán San Martin   | 1646 |\n",
    "| Tajuya near El Paso | 1585 |\n",
    "| Montaña Quemada     | 1492 |\n",
    "\n",
    "Table 1: Recent historic eruptions on La Palma\n",
    "\n",
    "<a href=\"#tbl-history\" class=\"quarto-xref\">Table 1</a> summarises the eruptions recorded since the colonization of the islands by Europeans in the late 1400s.\n",
    "\n",
    "<figure id=\"fig-map\">\n",
    "\n",
    "<img src=\"index.out 2_files/figure-html/230104d7-c37b-438c-93fd-5bab58bad4dd-1-images/la-palma-map.png\" />\n",
    "\n",
    "<figcaption>\n",
    "\n",
    "Figure 2: Map of La Palma\n",
    "\n",
    "</figcaption>\n",
    "\n",
    "</figure>\n",
    "\n",
    "La Palma is one of the west most islands in the Volcanic Archipelago of the Canary Islands (<a href=\"#fig-map\" class=\"quarto-xref\">Figure 2</a>).\n",
    "\n",
    "## 4 Data & Methods\n",
    "\n",
    "## 5 Conclusion\n",
    "\n",
    "## References\n",
    "\n",
    "Marrero, José, Alicia García, Manuel Berrocoso, Ángeles Llinares, Antonio Rodríguez-Losada, and R. Ortiz. 2019. “Strategies for the Development of Volcanic Hazard Maps in Monogenetic Volcanic Fields: The Example of La Palma (Canary Islands).” *Journal of Applied Volcanology* 8 (July). <https://doi.org/10.1186/s13617-019-0085-5>."
   ],
   "id": "230104d7-c37b-438c-93fd-5bab58bad4dd"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
