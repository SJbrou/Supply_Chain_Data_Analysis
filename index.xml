<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">

<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">

<front>
<journal-meta>
<journal-id></journal-id>

<journal-title-group>
<journal-title>Earth and Space Science</journal-title>
</journal-title-group>
<issn></issn>

<publisher>
<publisher-name></publisher-name>
</publisher>
</journal-meta>


<article-meta>


<title-group>
<article-title>Supply Chain Data Analytics</article-title>
<subtitle>Analyzing and Forcasting Supermarket Sales</subtitle>
</title-group>

<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Brouwer</surname>
<given-names>Stan</given-names>
</name>
<string-name>Stan Brouwer</string-name>

<xref ref-type="aff" rid="aff-1">a</xref>
<xref ref-type="corresp" rid="cor-1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chan</surname>
<given-names>Liz</given-names>
</name>
<string-name>Liz Chan</string-name>

<xref ref-type="aff" rid="aff-2">b</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lamberst</surname>
<given-names>Maaike</given-names>
</name>
<string-name>Maaike Lamberst</string-name>

<xref ref-type="aff" rid="aff-3">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schroor</surname>
<given-names>Niek</given-names>
</name>
<string-name>Niek Schroor</string-name>

<xref ref-type="aff" rid="aff-4">d</xref>
</contrib>
</contrib-group>
<aff id="aff-1">
<institution-wrap>
<institution>Vrije Universiteit</institution>
</institution-wrap>







</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Master TSCM</institution>
</institution-wrap>







</aff>
<aff id="aff-3">
<institution-wrap>
<institution>Supply Chain Data analysis</institution>
</institution-wrap>







</aff>
<aff id="aff-4">
<institution-wrap>
<institution>Group 10</institution>
</institution-wrap>







</aff>
<author-notes>
<corresp id="cor-1"></corresp>
</author-notes>

<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-12-07">
<year>2024</year>
<month>12</month>
<day>7</day>
</pub-date>







<history></history>






</article-meta>

</front>

<body>
<p>Introduction</p>
<p>We analyze, forecast and interpret the
<ext-link ext-link-type="uri" xlink:href="https://public.tableau.com/app/sample-data/sample_-_superstore.xls">Superstore
sales</ext-link> provided by
<ext-link ext-link-type="uri" xlink:href="https://public.tableau.com/app/learn/sample-data">Tableau</ext-link>
using different statistical and machine learning methods.</p>
<p>We describe our work in the PDF version. However, we would like to
recommend reading our quarto manuscript <italic>here</italic> as it
contains the <bold>relevant</bold> R code in the Article Notebook.</p>
<sec id="data-pre-processing">
  <title>1 Data Pre-processing</title>
  <p>The superstore data set we selected is of high quality. Thus we do
  the required data pre-processing, but included the hypothetical steps
  we would take were our data of lower quality to communicate our
  understanding of the data pre-processing process.</p>
  <p>We took the following pre-processing steps:</p>
  <list list-type="bullet">
    <list-item>
      <p>Improved column names by removing whitespaces</p>
    </list-item>
    <list-item>
      <p>Removed the Row_ID column as it can be inferred by it’s
      index</p>
    </list-item>
    <list-item>
      <p>Removed all columns with a single unique value, as storing
      these would be
      <ext-link ext-link-type="uri" xlink:href="https://few.vu.nl/~molenaar/courses/StatR/chapters/B-06-raw_data.html">redundant</ext-link></p>
    </list-item>
    <list-item>
      <p>Ensured machine-readable date formats in yyyy-mm-dd as these
      usually differ per locale.</p>
    </list-item>
    <list-item>
      <p>Ensured proper decimal separators</p>
    </list-item>
    <list-item>
      <p>Calculated the number of missing values (both NA and empty
      string ““) per column.</p>
    </list-item>
  </list>
  <preformat>[1] &quot;None of the columns contains missing values&quot;</preformat>
  <p>After these steps (and transposing the table for better document
  formatting), the data looks as follows:</p>
  <table-wrap>
    <caption>
      <p>First 5 Rows of the Data (Transposed)</p>
    </caption>
    <table>
      <colgroup>
        <col width="8%" />
        <col width="20%" />
        <col width="36%" />
        <col width="35%" />
      </colgroup>
      <tbody>
        <tr>
          <td align="left">Order_ID</td>
          <td align="left">CA-2016-152156</td>
          <td align="left">CA-2016-152156</td>
          <td align="left">CA-2016-138688</td>
        </tr>
        <tr>
          <td align="left">Order_Date</td>
          <td align="left">2016-11-08</td>
          <td align="left">2016-11-08</td>
          <td align="left">2016-06-12</td>
        </tr>
        <tr>
          <td align="left">Ship_Date</td>
          <td align="left">2016-11-11</td>
          <td align="left">2016-11-11</td>
          <td align="left">2016-06-16</td>
        </tr>
        <tr>
          <td align="left">Ship_Mode</td>
          <td align="left">Second Class</td>
          <td align="left">Second Class</td>
          <td align="left">Second Class</td>
        </tr>
        <tr>
          <td align="left">Customer_ID</td>
          <td align="left">CG-12520</td>
          <td align="left">CG-12520</td>
          <td align="left">DV-13045</td>
        </tr>
        <tr>
          <td align="left">Customer_Name</td>
          <td align="left">Claire Gute</td>
          <td align="left">Claire Gute</td>
          <td align="left">Darrin Van Huff</td>
        </tr>
        <tr>
          <td align="left">Segment</td>
          <td align="left">Consumer</td>
          <td align="left">Consumer</td>
          <td align="left">Corporate</td>
        </tr>
        <tr>
          <td align="left">City</td>
          <td align="left">Henderson</td>
          <td align="left">Henderson</td>
          <td align="left">Los Angeles</td>
        </tr>
        <tr>
          <td align="left">State</td>
          <td align="left">Kentucky</td>
          <td align="left">Kentucky</td>
          <td align="left">California</td>
        </tr>
        <tr>
          <td align="left">Postal_Code</td>
          <td align="left">42420</td>
          <td align="left">42420</td>
          <td align="left">90036</td>
        </tr>
        <tr>
          <td align="left">Region</td>
          <td align="left">South</td>
          <td align="left">South</td>
          <td align="left">West</td>
        </tr>
        <tr>
          <td align="left">Product_ID</td>
          <td align="left">FUR-BO-10001798</td>
          <td align="left">FUR-CH-10000454</td>
          <td align="left">OFF-LA-10000240</td>
        </tr>
        <tr>
          <td align="left">Category</td>
          <td align="left">Furniture</td>
          <td align="left">Furniture</td>
          <td align="left">Office Supplies</td>
        </tr>
        <tr>
          <td align="left">Sub_Category</td>
          <td align="left">Bookcases</td>
          <td align="left">Chairs</td>
          <td align="left">Labels</td>
        </tr>
        <tr>
          <td align="left">Product_Name</td>
          <td align="left">Bush Somerset Collection Bookcase</td>
          <td align="left">Hon Deluxe Fabric Upholstered Stacking
          Chairs, Rounded Back</td>
          <td align="left">Self-Adhesive Address Labels for Typewriters
          by Universal</td>
        </tr>
        <tr>
          <td align="left">Sales</td>
          <td align="left">261.96</td>
          <td align="left">731.94</td>
          <td align="left">14.62</td>
        </tr>
        <tr>
          <td align="left">Quantity</td>
          <td align="left">2</td>
          <td align="left">3</td>
          <td align="left">2</td>
        </tr>
        <tr>
          <td align="left">Discount</td>
          <td align="left">0</td>
          <td align="left">0</td>
          <td align="left">0</td>
        </tr>
        <tr>
          <td align="left">Profit</td>
          <td align="left">41.9136</td>
          <td align="left">219.5820</td>
          <td align="left">6.8714</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>There is some more processing to do, for instance the removal of
  outliers. However, by doing so we impose our own assumptions on the
  data. Let’s start by evaluating the descriptive statistics of our data
  and check if further processing is required.</p>
  <table-wrap>
    <caption>
      <p>Descriptive Statistics for Numeric Columns</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="left">Column</th>
          <th align="left">Min</th>
          <th align="left">Max</th>
          <th align="left">Mean</th>
          <th align="left">Median</th>
          <th align="left">StdDev</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left">Postal_Code</td>
          <td align="left">1040</td>
          <td align="left">99301</td>
          <td align="left">55190.38</td>
          <td align="left">56430.5</td>
          <td align="left">32063.69</td>
        </tr>
        <tr>
          <td align="left">Sales</td>
          <td align="left">0.444</td>
          <td align="left">22638.48</td>
          <td align="left">229.858</td>
          <td align="left">54.49</td>
          <td align="left">623.2451</td>
        </tr>
        <tr>
          <td align="left">Quantity</td>
          <td align="left">1</td>
          <td align="left">14</td>
          <td align="left">3.789574</td>
          <td align="left">3</td>
          <td align="left">2.22511</td>
        </tr>
        <tr>
          <td align="left">Discount</td>
          <td align="left">0</td>
          <td align="left">0.8</td>
          <td align="left">0.1562027</td>
          <td align="left">0.2</td>
          <td align="left">0.206452</td>
        </tr>
        <tr>
          <td align="left">Profit</td>
          <td align="left">-6599.978</td>
          <td align="left">8399.976</td>
          <td align="left">28.6569</td>
          <td align="left">8.6665</td>
          <td align="left">234.2601</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap>
    <caption>
      <p>Descriptive Statistics for Date Columns</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="left">Column</th>
          <th align="left">Earliest</th>
          <th align="left">Latest</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left">Order_Date</td>
          <td align="left">2014-01-03</td>
          <td align="left">2017-12-30</td>
        </tr>
        <tr>
          <td align="left">Ship_Date</td>
          <td align="left">2014-01-07</td>
          <td align="left">2018-01-05</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>We inspected the orders with the lowest and highers price (Sales in
  USD). The most expensive orders were professional printers, camera’s
  and teleconferencing units with high unit prices, and these orders
  often were of high Quantity. The orders with the lowest price where
  often binders, had a high Discount rate, and often a Quantity of just
  one.</p>
  <p>We were fascinated by the orders with a negative profit. These all
  had high Discount rates, and often concerned the same items, such as
  the Cubify CubeX 3D Printer Triple Head Print. The orders with a
  negative Profit where often part of a larger order (for instance
  CA-2016-108196), and placed by customers that placed multiple orders.
  We suspect these negative Profit’s to be caused by faulty items that
  receive discounts, general discount codes, or volume discounts.
  However, due to especially the high discounts on orders with negative
  profits, we assume these to be valid orders. This decision has also
  been influenced by the high quality of the data. As we found no
  missing values whats however, we suspect the chance of some weird but
  valid orders to be higher than encountering mistakes here.
  <italic>[this paragraph could use some rewriting]</italic></p>
  <p>In figure x we plotted the sales of the most popular products.
  Unfortunately, the sales of individual products were too low to
  determine any meaningfull trends.</p>
  <fig>
    <caption><p>Figure x Sale quantity of the most popular
    products</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/Quantity_top_products-1.png" />
  </fig>
  <p>Our proposed workaround is to aggregate products by their
  Sub_Category, and treating them as a single product for the rest of
  the assignment, which we plotted in figure X.</p>
  <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/Aggregated_Sub_Category_sales-1.png" />
  <p>These aggregated sales start to show trends and seasonality, and
  are much more useful to base predictions on! We will use these
  aggregated sub-categories for the rest of the assignment.</p>
  <p>To properly finish our data pre-processing we ran some statistics
  on the aggregated sub-category sales. Table x contains soem
  descriptive statistics.</p>
  <table-wrap>
    <caption>
      <p>Statistics for Sub_Category quantity</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="left">Sub_Category</th>
          <th align="right">Min</th>
          <th align="right">Mean</th>
          <th align="right">Max</th>
          <th align="right">Sd</th>
          <th align="right">CI_lower</th>
          <th align="right">CI_upper</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left">Accessories</td>
          <td align="right">1</td>
          <td align="right">3.84</td>
          <td align="right">14</td>
          <td align="right">2.28</td>
          <td align="right">3.68</td>
          <td align="right">4.00</td>
        </tr>
        <tr>
          <td align="left">Appliances</td>
          <td align="right">1</td>
          <td align="right">3.71</td>
          <td align="right">14</td>
          <td align="right">2.12</td>
          <td align="right">3.52</td>
          <td align="right">3.90</td>
        </tr>
        <tr>
          <td align="left">Art</td>
          <td align="right">1</td>
          <td align="right">3.77</td>
          <td align="right">14</td>
          <td align="right">2.13</td>
          <td align="right">3.62</td>
          <td align="right">3.92</td>
        </tr>
        <tr>
          <td align="left">Binders</td>
          <td align="right">1</td>
          <td align="right">3.92</td>
          <td align="right">14</td>
          <td align="right">2.29</td>
          <td align="right">3.80</td>
          <td align="right">4.04</td>
        </tr>
        <tr>
          <td align="left">Bookcases</td>
          <td align="right">1</td>
          <td align="right">3.81</td>
          <td align="right">13</td>
          <td align="right">2.28</td>
          <td align="right">3.51</td>
          <td align="right">4.11</td>
        </tr>
        <tr>
          <td align="left">Chairs</td>
          <td align="right">1</td>
          <td align="right">3.82</td>
          <td align="right">14</td>
          <td align="right">2.28</td>
          <td align="right">3.64</td>
          <td align="right">4.00</td>
        </tr>
        <tr>
          <td align="left">Copiers</td>
          <td align="right">1</td>
          <td align="right">3.44</td>
          <td align="right">9</td>
          <td align="right">1.83</td>
          <td align="right">3.01</td>
          <td align="right">3.87</td>
        </tr>
        <tr>
          <td align="left">Envelopes</td>
          <td align="right">1</td>
          <td align="right">3.57</td>
          <td align="right">9</td>
          <td align="right">2.05</td>
          <td align="right">3.32</td>
          <td align="right">3.82</td>
        </tr>
        <tr>
          <td align="left">Fasteners</td>
          <td align="right">1</td>
          <td align="right">4.21</td>
          <td align="right">14</td>
          <td align="right">2.41</td>
          <td align="right">3.89</td>
          <td align="right">4.53</td>
        </tr>
        <tr>
          <td align="left">Furnishings</td>
          <td align="right">1</td>
          <td align="right">3.72</td>
          <td align="right">14</td>
          <td align="right">2.16</td>
          <td align="right">3.58</td>
          <td align="right">3.86</td>
        </tr>
        <tr>
          <td align="left">Labels</td>
          <td align="right">1</td>
          <td align="right">3.85</td>
          <td align="right">14</td>
          <td align="right">2.35</td>
          <td align="right">3.61</td>
          <td align="right">4.09</td>
        </tr>
        <tr>
          <td align="left">Machines</td>
          <td align="right">1</td>
          <td align="right">3.83</td>
          <td align="right">11</td>
          <td align="right">2.17</td>
          <td align="right">3.43</td>
          <td align="right">4.23</td>
        </tr>
        <tr>
          <td align="left">Paper</td>
          <td align="right">1</td>
          <td align="right">3.78</td>
          <td align="right">14</td>
          <td align="right">2.23</td>
          <td align="right">3.66</td>
          <td align="right">3.90</td>
        </tr>
        <tr>
          <td align="left">Phones</td>
          <td align="right">1</td>
          <td align="right">3.70</td>
          <td align="right">14</td>
          <td align="right">2.19</td>
          <td align="right">3.56</td>
          <td align="right">3.84</td>
        </tr>
        <tr>
          <td align="left">Storage</td>
          <td align="right">1</td>
          <td align="right">3.73</td>
          <td align="right">14</td>
          <td align="right">2.19</td>
          <td align="right">3.58</td>
          <td align="right">3.88</td>
        </tr>
        <tr>
          <td align="left">Supplies</td>
          <td align="right">1</td>
          <td align="right">3.41</td>
          <td align="right">10</td>
          <td align="right">1.84</td>
          <td align="right">3.15</td>
          <td align="right">3.67</td>
        </tr>
        <tr>
          <td align="left">Tables</td>
          <td align="right">1</td>
          <td align="right">3.89</td>
          <td align="right">13</td>
          <td align="right">2.45</td>
          <td align="right">3.62</td>
          <td align="right">4.16</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>The statistics for the sales aggregated by product category look
  valid. We can further inspect them by visualizing them as histogram
  and visually check for anomalies. Figure y contains histograms of the
  quantities per sub-category.</p>
  <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/sub_category_histograms-1.png" />
  <p>The histograms show that the quantities are not normally
  distributed, but have a right-skewed distribution. This is expected as
  most orders contain a small number of items, but some orders contain a
  large number of items. We will not remove these outliers as they are
  valid orders.</p>
  <p>As the data we are going to use seems valid, we move on to
  exploring the trends and visualizing our data.</p>
</sec>
<sec id="data-visualization">
  <title>2 Data Visualization</title>
  <p>some text for the visualization</p>
</sec>
</body>

<back>
</back>

<sub-article article-type="notebook" id="nb-7-nb-article">
<front-stub>
<title-group>
<article-title>Supply Chain Data Analytics</article-title>
<subtitle>Analyzing and Forcasting Supermarket Sales</subtitle>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Brouwer</surname>
<given-names>Stan</given-names>
</name>
<string-name>Stan Brouwer</string-name>

<xref ref-type="aff" rid="aff-1-nb-article">a</xref>
<xref ref-type="corresp" rid="cor-1-nb-article">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chan</surname>
<given-names>Liz</given-names>
</name>
<string-name>Liz Chan</string-name>

<xref ref-type="aff" rid="aff-2-nb-article">b</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lamberst</surname>
<given-names>Maaike</given-names>
</name>
<string-name>Maaike Lamberst</string-name>

<xref ref-type="aff" rid="aff-3-nb-article">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schroor</surname>
<given-names>Niek</given-names>
</name>
<string-name>Niek Schroor</string-name>

<xref ref-type="aff" rid="aff-4-nb-article">d</xref>
</contrib>
</contrib-group>
<aff id="aff-1-nb-article">
<institution-wrap>
<institution>Vrije Universiteit</institution>
</institution-wrap>







</aff>
<aff id="aff-2-nb-article">
<institution-wrap>
<institution>Master TSCM</institution>
</institution-wrap>







</aff>
<aff id="aff-3-nb-article">
<institution-wrap>
<institution>Supply Chain Data analysis</institution>
</institution-wrap>







</aff>
<aff id="aff-4-nb-article">
<institution-wrap>
<institution>Group 10</institution>
</institution-wrap>







</aff>
<author-notes>
<corresp id="cor-1-nb-article"></corresp>
</author-notes>
</front-stub>

<body>
<p>Introduction</p>
<p>We analyze, forecast and interpret the
<ext-link ext-link-type="uri" xlink:href="https://public.tableau.com/app/sample-data/sample_-_superstore.xls">Superstore
sales</ext-link> provided by
<ext-link ext-link-type="uri" xlink:href="https://public.tableau.com/app/learn/sample-data">Tableau</ext-link>
using different statistical and machine learning methods.</p>
<p>We describe our work in the PDF version. However, we would like to
recommend reading our quarto manuscript <italic>here</italic> as it
contains the <bold>relevant</bold> R code in the Article Notebook.</p>
<sec id="data-pre-processing-nb-article">
  <title>1 Data Pre-processing</title>
  <p>The superstore data set we selected is of high quality. Thus we do
  the required data pre-processing, but included the hypothetical steps
  we would take were our data of lower quality to communicate our
  understanding of the data pre-processing process.</p>
  <p>We took the following pre-processing steps:</p>
  <sec specific-use="notebook-content">
  <code language="r script"># Clear workspace
rm(list = ls())
# Function to load (and install if necessary) dependencies
install_and_load &lt;- function(packages) {
  install.packages(setdiff(packages, rownames(installed.packages())), dependencies = TRUE)
  invisible(lapply(packages, require, character.only = TRUE))
}
install_and_load(c(&quot;tidyverse&quot;, &quot;readxl&quot;, &quot;ggplot2&quot;, &quot;lubridate&quot;, &quot;stats&quot;, &quot;Amelia&quot;,&quot;forecast&quot;, &quot;tseries&quot;, &quot;plotly&quot;, &quot;stringr&quot;, &quot;knitr&quot;))</code>
  <boxed-text>
    <preformat>Loading required package: tidyverse</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors
Loading required package: readxl

Loading required package: Amelia</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>Warning: package 'Amelia' was built under R version 4.3.3</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>Loading required package: Rcpp
## 
## Amelia II: Multiple Imputation
## (Version 1.8.3, built: 2024-11-07)
## Copyright (C) 2005-2024 James Honaker, Gary King and Matthew Blackwell
## Refer to http://gking.harvard.edu/amelia/ for more information
## 
Loading required package: forecast</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>Warning: package 'forecast' was built under R version 4.3.3</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>Registered S3 method overwritten by 'quantmod':
  method            from
  as.zoo.data.frame zoo 
Loading required package: tseries</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>Warning: package 'tseries' was built under R version 4.3.3</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>Loading required package: plotly

Attaching package: 'plotly'

The following object is masked from 'package:ggplot2':

    last_plot

The following object is masked from 'package:stats':

    filter

The following object is masked from 'package:graphics':

    layout

Loading required package: knitr</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>Warning: package 'knitr' was built under R version 4.3.3</preformat>
  </boxed-text>
  </sec>
  <list list-type="bullet">
    <list-item>
      <p>Improved column names by removing whitespaces</p>
    </list-item>
    <list-item>
      <p>Removed the Row_ID column as it can be inferred by it’s
      index</p>
    </list-item>
    <list-item>
      <p>Removed all columns with a single unique value, as storing
      these would be
      <ext-link ext-link-type="uri" xlink:href="https://few.vu.nl/~molenaar/courses/StatR/chapters/B-06-raw_data.html">redundant</ext-link></p>
    </list-item>
    <list-item>
      <p>Ensured machine-readable date formats in yyyy-mm-dd as these
      usually differ per locale.</p>
    </list-item>
    <list-item>
      <p>Ensured proper decimal separators</p>
    </list-item>
    <list-item>
      <p>Calculated the number of missing values (both NA and empty
      string ““) per column.</p>
    </list-item>
  </list>
  <sec specific-use="notebook-content">
  <code language="r script"># Load the data
suppressWarnings({data &lt;- read_excel(&quot;data/sample_-_superstore.xls&quot;)}) # The Postal code column is stored as 'text' but coerced to numeric, causing warnings which we suppress

# Improve column names
colnames(data) &lt;- str_replace_all(colnames(data), &quot; &quot;, &quot;_&quot;)
colnames(data) &lt;- str_replace_all(colnames(data), &quot;-&quot;, &quot;_&quot;)

# Remove the 'Row_ID' column as it can be inferred by it's index
data &lt;- subset(data, select = -`Row_ID`)

# Remove all columns that have only one unique value, as storing these would be redundant
data &lt;- data[, sapply(data, function(col) length(unique(col)) &gt; 1)]

# Ensure a machine-readable date format as these are usually horrible in excel files
data$Order_Date &lt;- as.Date(data$Order_Date, format = &quot;%Y-%m-%d&quot;)
data$Ship_Date &lt;- as.Date(data$Ship_Date, format = &quot;%Y-%m-%d&quot;)

# The readxl package by default uses the correct decimal separator (as opposed to base R)

# Calculate the number of missing values per column.
# Origional dates and R date objects are in unix time, which return NA when compared to text (empty string). These dates are stored as 'double' datatype, Thus we check character columns for empty strings, and all columns for NA values. 
missing_values &lt;- sapply(data, function(col) {
  if (inherits(col, &quot;Date&quot;)) {
    sum(is.na(col))
  } else if (is.character(col)) {
    sum(is.na(col) | col == &quot;&quot;)
  } else {
    sum(is.na(col))
  }
})


if (sum(missing_values) == 0) {
  print(&quot;None of the columns contains missing values&quot;) # We print to enforce the &quot;Source: Article notebook
  } else {
  print(&quot;Some columns contain missing values&quot;)
}</code>
  <boxed-text>
    <preformat>[1] &quot;None of the columns contains missing values&quot;</preformat>
  </boxed-text>
  <code language="r script"># Optionally, print the missing values as a nice table
missing_values_table &lt;- data.frame(
  Column = names(missing_values),
  Missing_or_Empty = missing_values
)
# Note that there are no missing values, thus we do not print them
# kable(missing_values_table, caption = &quot;Missing or Empty Values in Columns&quot;, format = &quot;pipe&quot;)


rm(missing_value, missing_values_table)</code>
  <boxed-text>
    <preformat>Warning in rm(missing_value, missing_values_table): object 'missing_value' not
found</preformat>
  </boxed-text>
  </sec>
  <p>After these steps (and transposing the table for better document
  formatting), the data looks as follows:</p>
  <sec specific-use="notebook-content">
  <code language="r script">kable(t(head(data, 3)), caption = &quot;First 5 Rows of the Data (Transposed)&quot;, format = &quot;markdown&quot;)</code>
  <table-wrap>
    <caption>
      <p>First 5 Rows of the Data (Transposed)</p>
    </caption>
    <table>
      <colgroup>
        <col width="8%" />
        <col width="20%" />
        <col width="36%" />
        <col width="35%" />
      </colgroup>
      <tbody>
        <tr>
          <td align="left">Order_ID</td>
          <td align="left">CA-2016-152156</td>
          <td align="left">CA-2016-152156</td>
          <td align="left">CA-2016-138688</td>
        </tr>
        <tr>
          <td align="left">Order_Date</td>
          <td align="left">2016-11-08</td>
          <td align="left">2016-11-08</td>
          <td align="left">2016-06-12</td>
        </tr>
        <tr>
          <td align="left">Ship_Date</td>
          <td align="left">2016-11-11</td>
          <td align="left">2016-11-11</td>
          <td align="left">2016-06-16</td>
        </tr>
        <tr>
          <td align="left">Ship_Mode</td>
          <td align="left">Second Class</td>
          <td align="left">Second Class</td>
          <td align="left">Second Class</td>
        </tr>
        <tr>
          <td align="left">Customer_ID</td>
          <td align="left">CG-12520</td>
          <td align="left">CG-12520</td>
          <td align="left">DV-13045</td>
        </tr>
        <tr>
          <td align="left">Customer_Name</td>
          <td align="left">Claire Gute</td>
          <td align="left">Claire Gute</td>
          <td align="left">Darrin Van Huff</td>
        </tr>
        <tr>
          <td align="left">Segment</td>
          <td align="left">Consumer</td>
          <td align="left">Consumer</td>
          <td align="left">Corporate</td>
        </tr>
        <tr>
          <td align="left">City</td>
          <td align="left">Henderson</td>
          <td align="left">Henderson</td>
          <td align="left">Los Angeles</td>
        </tr>
        <tr>
          <td align="left">State</td>
          <td align="left">Kentucky</td>
          <td align="left">Kentucky</td>
          <td align="left">California</td>
        </tr>
        <tr>
          <td align="left">Postal_Code</td>
          <td align="left">42420</td>
          <td align="left">42420</td>
          <td align="left">90036</td>
        </tr>
        <tr>
          <td align="left">Region</td>
          <td align="left">South</td>
          <td align="left">South</td>
          <td align="left">West</td>
        </tr>
        <tr>
          <td align="left">Product_ID</td>
          <td align="left">FUR-BO-10001798</td>
          <td align="left">FUR-CH-10000454</td>
          <td align="left">OFF-LA-10000240</td>
        </tr>
        <tr>
          <td align="left">Category</td>
          <td align="left">Furniture</td>
          <td align="left">Furniture</td>
          <td align="left">Office Supplies</td>
        </tr>
        <tr>
          <td align="left">Sub_Category</td>
          <td align="left">Bookcases</td>
          <td align="left">Chairs</td>
          <td align="left">Labels</td>
        </tr>
        <tr>
          <td align="left">Product_Name</td>
          <td align="left">Bush Somerset Collection Bookcase</td>
          <td align="left">Hon Deluxe Fabric Upholstered Stacking
          Chairs, Rounded Back</td>
          <td align="left">Self-Adhesive Address Labels for Typewriters
          by Universal</td>
        </tr>
        <tr>
          <td align="left">Sales</td>
          <td align="left">261.96</td>
          <td align="left">731.94</td>
          <td align="left">14.62</td>
        </tr>
        <tr>
          <td align="left">Quantity</td>
          <td align="left">2</td>
          <td align="left">3</td>
          <td align="left">2</td>
        </tr>
        <tr>
          <td align="left">Discount</td>
          <td align="left">0</td>
          <td align="left">0</td>
          <td align="left">0</td>
        </tr>
        <tr>
          <td align="left">Profit</td>
          <td align="left">41.9136</td>
          <td align="left">219.5820</td>
          <td align="left">6.8714</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  </sec>
  <p>There is some more processing to do, for instance the removal of
  outliers. However, by doing so we impose our own assumptions on the
  data. Let’s start by evaluating the descriptive statistics of our data
  and check if further processing is required.</p>
  <sec specific-use="notebook-content">
  <code language="r script">descriptive_statistics &lt;- function(column) {
  if (is.numeric(column)) {
    stats &lt;- list(
      Min = min(column, na.rm = TRUE), # Note that handling NA values increases robustness (and I copied the funciton from some of my earlier work)
      Max = max(column, na.rm = TRUE),
      Mean = mean(column, na.rm = TRUE),
      Median = median(column, na.rm = TRUE),
      StdDev = sd(column, na.rm = TRUE)
    )
  } else if (inherits(column, &quot;Date&quot;)) {
    stats &lt;- list(
      Earliest = format(min(column, na.rm = TRUE), &quot;%Y-%m-%d&quot;),
      Latest = format(max(column, na.rm = TRUE), &quot;%Y-%m-%d&quot;)
    )
  } else if (is.character(column)) {
    stats &lt;- list(
      Unique = length(unique(column)),
      Mode = names(sort(table(column), decreasing = TRUE)[1])
    )
  } else {
    stats &lt;- NULL
  }
  return(stats)
}

# Call function on dataframe
descriptive_stats &lt;- lapply(data, descriptive_statistics)

# Separate to tables dependent on data type
numeric_stats &lt;- as.data.frame(do.call(rbind, lapply(names(data), function(col_name) {
  if (is.numeric(data[[col_name]])) {
    c(Column = col_name, descriptive_stats[[col_name]])
  }
})), stringsAsFactors = FALSE)
date_stats &lt;- as.data.frame(do.call(rbind, lapply(names(data), function(col_name) {
  if (inherits(data[[col_name]], &quot;Date&quot;)) {
    c(Column = col_name, descriptive_stats[[col_name]])
  }
})), stringsAsFactors = FALSE)
character_stats &lt;- as.data.frame(do.call(rbind, lapply(names(data), function(col_name) {
  if (is.character(data[[col_name]])) {
    c(Column = col_name, descriptive_stats[[col_name]])
  }
})), stringsAsFactors = FALSE)

# Output tables
kable(
  numeric_stats,
  caption = &quot;Descriptive Statistics for Numeric Columns&quot;,
  format = &quot;pipe&quot;)</code>
  <table-wrap>
    <caption>
      <p>Descriptive Statistics for Numeric Columns</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="left">Column</th>
          <th align="left">Min</th>
          <th align="left">Max</th>
          <th align="left">Mean</th>
          <th align="left">Median</th>
          <th align="left">StdDev</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left">Postal_Code</td>
          <td align="left">1040</td>
          <td align="left">99301</td>
          <td align="left">55190.38</td>
          <td align="left">56430.5</td>
          <td align="left">32063.69</td>
        </tr>
        <tr>
          <td align="left">Sales</td>
          <td align="left">0.444</td>
          <td align="left">22638.48</td>
          <td align="left">229.858</td>
          <td align="left">54.49</td>
          <td align="left">623.2451</td>
        </tr>
        <tr>
          <td align="left">Quantity</td>
          <td align="left">1</td>
          <td align="left">14</td>
          <td align="left">3.789574</td>
          <td align="left">3</td>
          <td align="left">2.22511</td>
        </tr>
        <tr>
          <td align="left">Discount</td>
          <td align="left">0</td>
          <td align="left">0.8</td>
          <td align="left">0.1562027</td>
          <td align="left">0.2</td>
          <td align="left">0.206452</td>
        </tr>
        <tr>
          <td align="left">Profit</td>
          <td align="left">-6599.978</td>
          <td align="left">8399.976</td>
          <td align="left">28.6569</td>
          <td align="left">8.6665</td>
          <td align="left">234.2601</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <code language="r script">kable(
  date_stats,
  caption = &quot;Descriptive Statistics for Date Columns&quot;,
  format = &quot;pipe&quot;)</code>
  <table-wrap>
    <caption>
      <p>Descriptive Statistics for Date Columns</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="left">Column</th>
          <th align="left">Earliest</th>
          <th align="left">Latest</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left">Order_Date</td>
          <td align="left">2014-01-03</td>
          <td align="left">2017-12-30</td>
        </tr>
        <tr>
          <td align="left">Ship_Date</td>
          <td align="left">2014-01-07</td>
          <td align="left">2018-01-05</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <code language="r script"># Let's not render the character table as it contains little relevant information
#kable(
#  character_stats,
#  caption = &quot;Descriptive Statistics for Text Columns&quot;,
#  format = &quot;pipe&quot;)</code>
  </sec>
  <p>We inspected the orders with the lowest and highers price (Sales in
  USD). The most expensive orders were professional printers, camera’s
  and teleconferencing units with high unit prices, and these orders
  often were of high Quantity. The orders with the lowest price where
  often binders, had a high Discount rate, and often a Quantity of just
  one.</p>
  <p>We were fascinated by the orders with a negative profit. These all
  had high Discount rates, and often concerned the same items, such as
  the Cubify CubeX 3D Printer Triple Head Print. The orders with a
  negative Profit where often part of a larger order (for instance
  CA-2016-108196), and placed by customers that placed multiple orders.
  We suspect these negative Profit’s to be caused by faulty items that
  receive discounts, general discount codes, or volume discounts.
  However, due to especially the high discounts on orders with negative
  profits, we assume these to be valid orders. This decision has also
  been influenced by the high quality of the data. As we found no
  missing values whats however, we suspect the chance of some weird but
  valid orders to be higher than encountering mistakes here.
  <italic>[this paragraph could use some rewriting]</italic></p>
  <p>In figure x we plotted the sales of the most popular products.
  Unfortunately, the sales of individual products were too low to
  determine any meaningfull trends.</p>
  <sec specific-use="notebook-content">
  <code language="r script"># Optionally: print top 10 sale quantity barplot
# # Sum of Quantity for top products
# top_products &lt;- data %&gt;%
#   group_by(Product_Name) %&gt;%
#   summarize(total_quantity = sum(Quantity, na.rm = TRUE)) %&gt;%
#   arrange(desc(total_quantity)) %&gt;%
#   slice_head(n = 10) %&gt;% 
#   mutate(ProdName8 = substr(Product_Name, 1, 8)) # Truncate product names to the first 8 characters. Long names mess up formatting
# 
# # Plot
# ggplot(top_products, aes(x = reorder(ProdName8, -total_quantity), y = total_quantity)) +
#   geom_bar(stat = &quot;identity&quot;, fill = &quot;steelblue&quot;) +
#   labs(title = &quot;Top 20 Most Sold Products&quot;,
#        x = &quot;Product ID&quot;,
#        y = &quot;Total Quantity&quot;) +
#   theme_minimal() +
#   coord_flip()

# Aggregate quantity by Product Name and Order Date to create a time series
time_series_data &lt;- data %&gt;%
  group_by(Product_Name, Order_Date) %&gt;%
  summarize(total_quantity = sum(Quantity, na.rm = TRUE)) %&gt;%
  ungroup()</code>
  <boxed-text>
    <preformat>`summarise()` has grouped output by 'Product_Name'. You can override using the
`.groups` argument.</preformat>
  </boxed-text>
  <code language="r script"># Filter for the top products by total quantity sold (adjust as needed)
top_products &lt;- time_series_data %&gt;%
  group_by(Product_Name) %&gt;%
  summarize(total_quantity = sum(total_quantity)) %&gt;%
  arrange(desc(total_quantity)) %&gt;%
  slice_head(n = 10)  # Select top 10 products

# Filter the time-series data for only these top products
filtered_time_series_data &lt;- time_series_data %&gt;%
  filter(Product_Name %in% top_products$Product_Name) %&gt;%
  mutate(ProdName10 = substr(Product_Name, 1, 10)) # Product names can be quite long and mess up layouts. Lets only plot the first 10 chars.

# Here we do some special plotting. We want to show the plot with only one selected line by default, but make sure that the other 9 top sold products can be selected. We first create the ggplotly object, and than modify the visibility of the traces

# Creating the ggplotly object
p_ly &lt;- ggplotly(ggplot(filtered_time_series_data, aes(x = Order_Date, y = total_quantity, color = ProdName10)) +
  geom_line(size = 1) +
  labs(title = &quot;Quantity Sold Over Time per Product&quot;,
       x = &quot;Order Date&quot;,
       y = &quot;Quantity Sold&quot;) +
  theme_minimal() +
  theme(legend.position = &quot;bottom&quot;) +
  scale_color_discrete(name = &quot;Product Name&quot;))</code>
  <boxed-text>
    <preformat>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</preformat>
  </boxed-text>
  <code language="r script"># Modify the visibility of traces
for (i in seq_along(p_ly$x$data)) {
  if (i == 1) {
    p_ly$x$data[[i]]$visible &lt;- TRUE  # Make the first trace visible
  } else {
    p_ly$x$data[[i]]$visible &lt;- &quot;legendonly&quot;  # Hide the rest
  }
}

# Plot
p_ly</code>
  <fig>
    <caption><p>Figure x Sale quantity of the most popular
    products</p></caption>
    <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/Quantity_top_products-1.png" />
  </fig>
  </sec>
  <p>Our proposed workaround is to aggregate products by their
  Sub_Category, and treating them as a single product for the rest of
  the assignment, which we plotted in figure X.</p>
  <sec specific-use="notebook-content">
  <code language="r script"># Bar plots

# # Count frequency of top 20 products
# top_products &lt;- data %&gt;%
#   count(Product_Name, sort = TRUE) %&gt;%
#   top_n(20, n) %&gt;%
#   mutate(ProdName8 = substr(Product_Name, 1, 8))
# 
# # Plot!
# ggplot(top_products, aes(x = reorder(`ProdName8`, -n), y = n)) +
#   geom_bar(stat = &quot;identity&quot;, fill = &quot;steelblue&quot;) +
#   labs(title = &quot;Top 20 Most Sold Products&quot;,
#        x = &quot;Product Name&quot;,
#        y = &quot;Quantity sold&quot;) +
#   theme_minimal() +
#   coord_flip()
# 
# Count frequency of top 20 products
top_categories &lt;- data %&gt;%
  count(Sub_Category, sort = TRUE)
# 
# # Plot!
# ggplot(top_categories, aes(x = reorder(Sub_Category, -n), y = n)) +
#   geom_bar(stat = &quot;identity&quot;, fill = &quot;steelblue&quot;) +
#   labs(title = &quot;Sub_Categories sorted&quot;,
#        x = &quot;Product Name&quot;,
#        y = &quot;Quantity sold&quot;) +
#   theme_minimal() +
#   coord_flip()

# Find top 10 most sold product names
top_10_categories &lt;- top_categories$Sub_Category[0:10]

# Filter the data for  top 10 products
top_10_data &lt;- data %&gt;% filter(Sub_Category %in% top_10_categories)

# calculate sales per month
top_10_data &lt;- top_10_data %&gt;%
  mutate(Month = floor_date(Order_Date, unit = &quot;month&quot;))

# Aggregate data by month for each sub-category
top_10_data_aggregated &lt;- top_10_data %&gt;%
  group_by(Month, Sub_Category) %&gt;%
  summarise(Sales_Count = n(), .groups = 'drop')

# Some special interactive plot formatting (see previous plot)
p_ly &lt;- ggplotly(ggplot(top_10_data_aggregated, aes(x = Month, y = Sales_Count, color = Sub_Category, group = Sub_Category)) +
    geom_line(size = 1) +
    geom_point(size = 2) +
    labs(title = &quot;Monthly Sales for the Top 3 Most Sold Products&quot;,
         x = &quot;Month&quot;,
         y = &quot;Sales Count&quot;,
         color = &quot;Product Name&quot;) +
    theme_minimal())

# Modify the visibility of traces
for (i in seq_along(p_ly$x$data)) {
  if (i == 1) {
    p_ly$x$data[[i]]$visible &lt;- TRUE  # Make the first trace visible
  } else {
    p_ly$x$data[[i]]$visible &lt;- &quot;legendonly&quot;  # Hide the rest
  }
}

# Plot
p_ly</code>
  <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/Aggregated_Sub_Category_sales-1.png" />
  </sec>
  <p>These aggregated sales start to show trends and seasonality, and
  are much more useful to base predictions on! We will use these
  aggregated sub-categories for the rest of the assignment.</p>
  <p>To properly finish our data pre-processing we ran some statistics
  on the aggregated sub-category sales. Table x contains soem
  descriptive statistics.</p>
  <sec specific-use="notebook-content">
  <code language="r script">library(dplyr)
library(kableExtra)</code>
  <boxed-text>
    <preformat>
Attaching package: 'kableExtra'</preformat>
  </boxed-text>
  <boxed-text>
    <preformat>The following object is masked from 'package:dplyr':

    group_rows</preformat>
  </boxed-text>
  <code language="r script"># Summarize the data
outlier_summary &lt;- data %&gt;%
  group_by(Sub_Category) %&gt;%
  summarize(
    Min = round(min(Quantity), 2),
    Mean = round(mean(Quantity), 2),
    Max = round(max(Quantity), 2),
    Sd = round(sd(Quantity), 2),
    CI_lower = round(Mean - 1.96 * (Sd / sqrt(n())), 2),
    CI_upper = round(Mean + 1.96 * (Sd / sqrt(n())), 2),
    .groups = &quot;drop&quot;
  )


# Output tables
kable(
  outlier_summary,
  caption = &quot;Statistics for Sub_Category quantity&quot;,
  format = &quot;pipe&quot;)</code>
  <table-wrap>
    <caption>
      <p>Statistics for Sub_Category quantity</p>
    </caption>
    <table>
      <thead>
        <tr>
          <th align="left">Sub_Category</th>
          <th align="right">Min</th>
          <th align="right">Mean</th>
          <th align="right">Max</th>
          <th align="right">Sd</th>
          <th align="right">CI_lower</th>
          <th align="right">CI_upper</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left">Accessories</td>
          <td align="right">1</td>
          <td align="right">3.84</td>
          <td align="right">14</td>
          <td align="right">2.28</td>
          <td align="right">3.68</td>
          <td align="right">4.00</td>
        </tr>
        <tr>
          <td align="left">Appliances</td>
          <td align="right">1</td>
          <td align="right">3.71</td>
          <td align="right">14</td>
          <td align="right">2.12</td>
          <td align="right">3.52</td>
          <td align="right">3.90</td>
        </tr>
        <tr>
          <td align="left">Art</td>
          <td align="right">1</td>
          <td align="right">3.77</td>
          <td align="right">14</td>
          <td align="right">2.13</td>
          <td align="right">3.62</td>
          <td align="right">3.92</td>
        </tr>
        <tr>
          <td align="left">Binders</td>
          <td align="right">1</td>
          <td align="right">3.92</td>
          <td align="right">14</td>
          <td align="right">2.29</td>
          <td align="right">3.80</td>
          <td align="right">4.04</td>
        </tr>
        <tr>
          <td align="left">Bookcases</td>
          <td align="right">1</td>
          <td align="right">3.81</td>
          <td align="right">13</td>
          <td align="right">2.28</td>
          <td align="right">3.51</td>
          <td align="right">4.11</td>
        </tr>
        <tr>
          <td align="left">Chairs</td>
          <td align="right">1</td>
          <td align="right">3.82</td>
          <td align="right">14</td>
          <td align="right">2.28</td>
          <td align="right">3.64</td>
          <td align="right">4.00</td>
        </tr>
        <tr>
          <td align="left">Copiers</td>
          <td align="right">1</td>
          <td align="right">3.44</td>
          <td align="right">9</td>
          <td align="right">1.83</td>
          <td align="right">3.01</td>
          <td align="right">3.87</td>
        </tr>
        <tr>
          <td align="left">Envelopes</td>
          <td align="right">1</td>
          <td align="right">3.57</td>
          <td align="right">9</td>
          <td align="right">2.05</td>
          <td align="right">3.32</td>
          <td align="right">3.82</td>
        </tr>
        <tr>
          <td align="left">Fasteners</td>
          <td align="right">1</td>
          <td align="right">4.21</td>
          <td align="right">14</td>
          <td align="right">2.41</td>
          <td align="right">3.89</td>
          <td align="right">4.53</td>
        </tr>
        <tr>
          <td align="left">Furnishings</td>
          <td align="right">1</td>
          <td align="right">3.72</td>
          <td align="right">14</td>
          <td align="right">2.16</td>
          <td align="right">3.58</td>
          <td align="right">3.86</td>
        </tr>
        <tr>
          <td align="left">Labels</td>
          <td align="right">1</td>
          <td align="right">3.85</td>
          <td align="right">14</td>
          <td align="right">2.35</td>
          <td align="right">3.61</td>
          <td align="right">4.09</td>
        </tr>
        <tr>
          <td align="left">Machines</td>
          <td align="right">1</td>
          <td align="right">3.83</td>
          <td align="right">11</td>
          <td align="right">2.17</td>
          <td align="right">3.43</td>
          <td align="right">4.23</td>
        </tr>
        <tr>
          <td align="left">Paper</td>
          <td align="right">1</td>
          <td align="right">3.78</td>
          <td align="right">14</td>
          <td align="right">2.23</td>
          <td align="right">3.66</td>
          <td align="right">3.90</td>
        </tr>
        <tr>
          <td align="left">Phones</td>
          <td align="right">1</td>
          <td align="right">3.70</td>
          <td align="right">14</td>
          <td align="right">2.19</td>
          <td align="right">3.56</td>
          <td align="right">3.84</td>
        </tr>
        <tr>
          <td align="left">Storage</td>
          <td align="right">1</td>
          <td align="right">3.73</td>
          <td align="right">14</td>
          <td align="right">2.19</td>
          <td align="right">3.58</td>
          <td align="right">3.88</td>
        </tr>
        <tr>
          <td align="left">Supplies</td>
          <td align="right">1</td>
          <td align="right">3.41</td>
          <td align="right">10</td>
          <td align="right">1.84</td>
          <td align="right">3.15</td>
          <td align="right">3.67</td>
        </tr>
        <tr>
          <td align="left">Tables</td>
          <td align="right">1</td>
          <td align="right">3.89</td>
          <td align="right">13</td>
          <td align="right">2.45</td>
          <td align="right">3.62</td>
          <td align="right">4.16</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  </sec>
  <p>The statistics for the sales aggregated by product category look
  valid. We can further inspect them by visualizing them as histogram
  and visually check for anomalies. Figure y contains histograms of the
  quantities per sub-category.</p>
  <sec specific-use="notebook-content">
  <code language="r script">sub_categories &lt;- unique(data$Sub_Category)

p &lt;- plot_ly()
for (i in seq_along(sub_categories)) {
  sub &lt;- sub_categories[i]
  subset_data &lt;- data %&gt;% filter(Sub_Category == sub)
  p &lt;- add_trace(
    p,
    x = subset_data$Quantity,
    type = &quot;histogram&quot;,
    name = sub,
    visible = ifelse(i == 1, TRUE, FALSE)
  )
}

# We add a drop down menu for Sub_Category as toggling visibility in default ggplot2 adds the histograms up. Instead we want to be able to show each histogram seperately. 
dropdown_buttons &lt;- lapply(seq_along(sub_categories), function(i) {
  list(
    method = &quot;update&quot;,
    args = list(
      list(visible = lapply(seq_along(sub_categories), function(j) j == i)),
      list(xaxis = list(title = &quot;Quantity&quot;, autorange = TRUE), 
           yaxis = list(title = &quot;Frequency&quot;, autorange = TRUE))
    ),
    label = sub_categories[i]
  )
})

# Style drop down layout
p &lt;- p %&gt;%
  layout(
    title = &quot;Distribution of Quantity Sold per Order by Sub-Category&quot;,
    xaxis = list(title = &quot;Quantity&quot;),
    yaxis = list(title = &quot;Frequency&quot;),
    showlegend = FALSE,  # Drop down instead of legend
    updatemenus = list(
      list(
        type = &quot;dropdown&quot;,
        buttons = dropdown_buttons,
        direction = &quot;down&quot;,
        x = 0.99,
        y = 0.99,
        showactive = TRUE,
        xanchor = &quot;left&quot;,
        yanchor = &quot;top&quot;
      )
    )
  )
p</code>
  <graphic mimetype="image" mime-subtype="png" xlink:href="index_files/figure-jats/sub_category_histograms-1.png" />
  </sec>
  <p>The histograms show that the quantities are not normally
  distributed, but have a right-skewed distribution. This is expected as
  most orders contain a small number of items, but some orders contain a
  large number of items. We will not remove these outliers as they are
  valid orders.</p>
  <p>As the data we are going to use seems valid, we move on to
  exploring the trends and visualizing our data.</p>
</sec>
<sec id="data-visualization-nb-article">
  <title>2 Data Visualization</title>
  <p>some text for the visualization</p>
</sec>
</body>



<back>
</back>


</sub-article>
<sub-article article-type="notebook" id="nb-3-nb-1">
<front-stub>
<title-group>
<article-title>Supply Chain Data Analytics</article-title>
</title-group>
</front-stub>

<body>
<sec id="cell-849b3526-cc7a-49ca-a916-949194fa166d-nb-1" specific-use="notebook-content">
<p>Analyzing and Forcasting Supermarket Sales</p>
<p>Stan Brouwer (Vrije Universiteit)
Liz Chan (Master TSCM)
Maaike Lamberst (Supply Chain Data analysis)
Niek Schroor (Group 10)
December 5, 2024</p>
</sec>
<sec id="cell-5bd31506-0b72-4bf6-9fa2-790dcf547f9e-nb-1" specific-use="notebook-content">
</sec>
<sec id="da879eaf-acfa-4518-9b60-82eaed332469-nb-1" specific-use="notebook-content">
<p>Introduction</p>
</sec>
<sec id="cell-4907d4ff-82b5-47d9-8daf-5c22039972ba-nb-1" specific-use="notebook-content">
</sec>
<sec id="d7d31d56-c042-4b60-bba3-cd7e90f2ebff-nb-1" specific-use="notebook-content">
<p>We analyze, forecast and interpret the
<ext-link ext-link-type="uri" xlink:href="https://public.tableau.com/app/sample-data/sample_-_superstore.xls">Superstore
sales</ext-link> provided by
<ext-link ext-link-type="uri" xlink:href="https://public.tableau.com/app/learn/sample-data">Tableau</ext-link>
using different statistical and machine learning methods.</p>
<p>We describe our work in the PDF version. However, we would like to
recommend reading our quarto manuscript <italic>here</italic> as it
contains the <bold>relevant</bold> R code in the Article Notebook.</p>
<sec id="data-pre-processing-nb-1">
  <title>1 Data Pre-processing</title>
  <p>The superstore data set we selected is of high quality. Thus we do
  the required data pre-processing, but included the hypothetical steps
  we would take were our data of lower quality to communicate our
  understanding of the data pre-processing process.</p>
  <p>We took the following pre-processing steps:</p>
  </sec>
  <sec id="cell-69337c99-6b39-4ce9-a6d4-cc534cdb0f4f-nb-1" specific-use="notebook-content">
  <code language="python"># Clear workspace
rm(list = ls())
# Function to load (and install if necessary) dependencies
install_and_load &lt;- function(packages) {
  install.packages(setdiff(packages, rownames(installed.packages())), dependencies = TRUE)
  invisible(lapply(packages, require, character.only = TRUE))
}
install_and_load(c(&quot;tidyverse&quot;, &quot;readxl&quot;, &quot;ggplot2&quot;, &quot;lubridate&quot;, &quot;stats&quot;, &quot;Amelia&quot;,&quot;forecast&quot;, &quot;tseries&quot;, &quot;plotly&quot;, &quot;stringr&quot;, &quot;knitr&quot;))</code>
  <boxed-text>
    <preformat>Loading required package: tidyverse── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors
Loading required package: readxl

Loading required package: AmeliaWarning: package 'Amelia' was built under R version 4.3.3Loading required package: Rcpp
## 
## Amelia II: Multiple Imputation
## (Version 1.8.3, built: 2024-11-07)
## Copyright (C) 2005-2024 James Honaker, Gary King and Matthew Blackwell
## Refer to http://gking.harvard.edu/amelia/ for more information
## 
Loading required package: forecastWarning: package 'forecast' was built under R version 4.3.3Registered S3 method overwritten by 'quantmod':
  method            from
  as.zoo.data.frame zoo 
Loading required package: tseriesWarning: package 'tseries' was built under R version 4.3.3Loading required package: plotly

Attaching package: 'plotly'

The following object is masked from 'package:ggplot2':

    last_plot

The following object is masked from 'package:stats':

    filter

The following object is masked from 'package:graphics':

    layout

Loading required package: knitrWarning: package 'knitr' was built under R version 4.3.3</preformat>
  </boxed-text>
  </sec>
  <sec id="cell-08adf834-669a-4137-ac53-473ed9f3c46a-nb-1" specific-use="notebook-content">
  <list list-type="bullet">
    <list-item>
      <p>Improved column names by removing whitespaces</p>
    </list-item>
    <list-item>
      <p>Removed the Row_ID column as it can be inferred by it’s
      index</p>
    </list-item>
    <list-item>
      <p>Removed all columns with a single unique value, as storing
      these would be
      <ext-link ext-link-type="uri" xlink:href="https://few.vu.nl/~molenaar/courses/StatR/chapters/B-06-raw_data.html">redundant</ext-link></p>
    </list-item>
    <list-item>
      <p>Ensured machine-readable date formats in yyyy-mm-dd as these
      usually differ per locale.</p>
    </list-item>
    <list-item>
      <p>Ensured proper decimal separators</p>
    </list-item>
    <list-item>
      <p>calculated the number of missing values (both NA and empty
      string ““) per column.</p>
    </list-item>
  </list>
  </sec>
  <sec id="cell-148d8508-c7d2-4e80-929a-2b1b6cd11f65-nb-1" specific-use="notebook-content">
  <code language="python"># Load the data
suppressWarnings({data &lt;- read_excel(&quot;data/sample_-_superstore.xls&quot;)}) # The Postal code column is stored as 'text' but coerced to numeric, causing warnings which we suppress

# Improve column names (replace &quot; &quot;with &quot;_&quot;)
colnames(data) &lt;- str_replace_all(colnames(data), &quot; &quot;, &quot;_&quot;)

# Remove the 'Row_ID' column as it can be inferred by it's index
data &lt;- subset(data, select = -`Row_ID`)

# Remove all columns that have only one unique value, as storing these would be redundant
data &lt;- data[, sapply(data, function(col) length(unique(col)) &gt; 1)]

# Ensure a machine-readable date format as these are usually horrible in excel files
data$Order_Date &lt;- as.Date(data$Order_Date, format = &quot;%Y-%m-%d&quot;)
data$Ship_Date &lt;- as.Date(data$Ship_Date, format = &quot;%Y-%m-%d&quot;)

# The readxl package by default uses the correct decimal separator (as opposed to base R)

# Calculate the number of missing values per column.
# The sample dates are likely in Unix time, and when these are converted to R date objects they are stored as Date objects (which are represented by 'double' datatypes). Comparing these dates to characters (empty strings) results in NA values. Thus we only check date values for NA. As Date objects are stored as doubles within R (amount of days since 1970-01-01), we can't check numeric columns for &quot; &quot; either. We thus only check character columns for &quot; &quot;.
missing_values &lt;- sapply(data, function(col) {
  if (inherits(col, &quot;Date&quot;)) {
    sum(is.na(col))
  } else if (is.character(col)) {
    sum(is.na(col) | col == &quot;&quot;)
  } else {
    sum(is.na(col))
  }
})

if (sum(missing_values) == 0) {
  print(&quot;No missing values&quot;)
}</code>
  <boxed-text>
    <preformat>[1] &quot;No missing values&quot;</preformat>
  </boxed-text>
  </sec>
  <sec id="b81e65cc-f83b-436e-b1e3-c1e79af543ad-nb-1" specific-use="notebook-content">
  <p>We also ran some descriptive statistics to check unlikely or
  impossible values, outliers, means, etc.</p>
  </sec>
  <sec id="cell-412655fd-4fc4-4406-a922-2a189b0c861e-nb-1" specific-use="notebook-content">
  <code language="python"># Select only numerical columns
numerical_data &lt;- data %&gt;% select_if(is.numeric)

# Apply sapply to calculate descriptive statistics for each numeric column
descriptive_stats &lt;- sapply(numerical_data, function(col) {
  # Remove NA values
  col &lt;- na.omit(col)
  
  # Calculate basic statistics
  min_val &lt;- min(col)
  max_val &lt;- max(col)
  mean_val &lt;- mean(col)
  median_val &lt;- median(col)
  
  # 95% Confidence Interval (assuming normal distribution)
  se &lt;- sd(col) / sqrt(length(col))  # Standard error
  ci_lower &lt;- mean_val - 1.96 * se  # Lower bound of 95% CI
  ci_upper &lt;- mean_val + 1.96 * se  # Upper bound of 95% CI
  
  # Calculate outliers (using 1.5 * IQR rule)
  Q1 &lt;- quantile(col, 0.25)
  Q3 &lt;- quantile(col, 0.75)
  IQR &lt;- Q3 - Q1
  outliers &lt;- sum(col &lt; (Q1 - 1.5 * IQR) | col &gt; (Q3 + 1.5 * IQR))  # Number of outliers
  
  # Return the statistics as a named vector
  return(c(Min = min_val, 
           Mean = mean_val, 
           Max = max_val, 
           Median = median_val, 
           `95% CI Lower` = ci_lower, 
           `95% CI Upper` = ci_upper, 
           Outliers = outliers))
})
head(data,5)</code>
  <boxed-text>
    <preformat># A tibble: 5 × 19
  Order_ID     Order_Date Ship_Date  Ship_Mode Customer_ID Customer_Name Segment
  &lt;chr&gt;        &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;         &lt;chr&gt;  
1 CA-2016-152… 2016-11-08 2016-11-11 Second C… CG-12520    Claire Gute   Consum…
2 CA-2016-152… 2016-11-08 2016-11-11 Second C… CG-12520    Claire Gute   Consum…
3 CA-2016-138… 2016-06-12 2016-06-16 Second C… DV-13045    Darrin Van H… Corpor…
4 US-2015-108… 2015-10-11 2015-10-18 Standard… SO-20335    Sean O'Donne… Consum…
5 US-2015-108… 2015-10-11 2015-10-18 Standard… SO-20335    Sean O'Donne… Consum…
# ℹ 12 more variables: City &lt;chr&gt;, State &lt;chr&gt;, Postal_Code &lt;dbl&gt;,
#   Region &lt;chr&gt;, Product_ID &lt;chr&gt;, Category &lt;chr&gt;, `Sub-Category` &lt;chr&gt;,
#   Product_Name &lt;chr&gt;, Sales &lt;dbl&gt;, Quantity &lt;dbl&gt;, Discount &lt;dbl&gt;,
#   Profit &lt;dbl&gt;</preformat>
  </boxed-text>
  </sec>
  <sec id="f1aa39cb-136f-4f96-a52b-52a1135a912c-nb-1" specific-use="notebook-content">
  <p>There is some more processing to do, such as removing outliers.
  However, by doing so we impose our own assumptions on the data
  (possibly the outliers are actual sales?). We will visualize and
  qualitatively evaluate the data first, and then decide what other
  processing steps to take.</p>
  </sec>
  <sec id="cell-25ab37f1-d368-4c61-b41e-481172c82c7f-nb-1" specific-use="notebook-content">
  <code language="python"># Display the first 5 rows of the data in a nice table with kable
kable(head(data,5), caption = &quot;First 5 Rows of the Data&quot;, format = &quot;pipe&quot;)</code>
  <boxed-text>
  </boxed-text>
  </sec>
  <sec id="ca73d308-b7d2-43a9-80ad-e80854581beb-nb-1" specific-use="notebook-content">
</sec>
<sec id="section-nb-1">
  <title>2 Section</title>
  <p>This is a simple placeholder for the manuscript’s main document
  (<xref alt="knuth84?" rid="ref-knuth84-nb-1" ref-type="bibr"><bold>knuth84?</bold></xref>).</p>
  </sec>
  <sec id="cell-9c2fcecf-6445-4cc8-9218-b666bcdca55b-nb-1" specific-use="notebook-content">
  <code language="python">1 + 1</code>
  <boxed-text>
    <preformat>[1] 2</preformat>
  </boxed-text>
  </sec>
  <sec id="cell-20fe86a8-1a18-436d-a6f8-4ad67175020a-nb-1" specific-use="notebook-content">
</sec>
<sec id="introduction-nb-1">
  <title>3 Introduction</title>
  </sec>
  <sec id="af4d3d8d-1d5f-40ea-b014-2334e82bd866-nb-1" specific-use="notebook-content">
  <code language="python">eruptions &lt;- c(1492, 1585, 1646, 1677, 1712, 1949, 1971, 2021)
n_eruptions &lt;- length(eruptions)</code>
  </sec>
  <sec id="cell-fig-timeline-nb-1" specific-use="notebook-content">
  <code language="python">par(mar = c(3, 1, 1, 1) + 0.1)
plot(eruptions, rep(0, n_eruptions), 
  pch = &quot;|&quot;, axes = FALSE)
axis(1)
box()</code>
  <boxed-text>
  </boxed-text>
  </sec>
  <sec id="cell-74d96b0e-38ba-40e4-8a00-2874e7deed9e-nb-1" specific-use="notebook-content">
  <code language="python">avg_years_between_eruptions &lt;- mean(diff(eruptions[-n_eruptions]))
avg_years_between_eruptions</code>
  <boxed-text>
    <preformat>[1] 79.83333</preformat>
  </boxed-text>
  </sec>
  <sec id="cell-230104d7-c37b-438c-93fd-5bab58bad4dd-nb-1" specific-use="notebook-content">
  <p>Based on data up to and including 1971, eruptions on La Palma
  happen every 79.8 years on average.</p>
  <p>Studies of the magma systems feeding the volcano, such as Marrero
  et
  al. (<xref alt="2019" rid="ref-marrero2019-nb-1" ref-type="bibr">2019</xref>),
  have proposed that there are two main magma reservoirs feeding the
  Cumbre Vieja volcano; one in the mantle (30-40km depth) which charges
  and in turn feeds a shallower crustal reservoir (10-20km depth).</p>
  <p>Eight eruptions have been recorded since the late 1400s
  (Figure 1).</p>
  <p>Data and methods are discussed in Section 4.</p>
  <p>Let <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  denote the number of eruptions in a year. Then,
  <inline-formula><alternatives>
  <tex-math><![CDATA[x]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>x</mml:mi></mml:math></alternatives></inline-formula>
  can be modeled by a Poisson distribution</p>
  <p><styled-content id="eq-poisson-nb-1"><disp-formula><alternatives>
  <tex-math><![CDATA[
  p(x) = \frac{e^{-\lambda} \lambda^{x}}{x !}
   \qquad(1)]]></tex-math>
  <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>−</mml:mi><mml:mi>λ</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mi>λ</mml:mi><mml:mi>x</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>!</mml:mi></mml:mrow></mml:mfrac><mml:mspace width="2.0em"></mml:mspace><mml:mrow><mml:mo stretchy="true" form="prefix">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="true" form="postfix">)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></styled-content></p>
  <p>where <inline-formula><alternatives>
  <tex-math><![CDATA[\lambda]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>λ</mml:mi></mml:math></alternatives></inline-formula>
  is the rate of eruptions per year. Using Equation 1, the probability
  of an eruption in the next <inline-formula><alternatives>
  <tex-math><![CDATA[t]]></tex-math>
  <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>t</mml:mi></mml:math></alternatives></inline-formula>
  years can be calculated.</p>
  <table-wrap>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Year</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Current</td>
          <td>2021</td>
        </tr>
        <tr>
          <td>Teneguía</td>
          <td>1971</td>
        </tr>
        <tr>
          <td>Nambroque</td>
          <td>1949</td>
        </tr>
        <tr>
          <td>El Charco</td>
          <td>1712</td>
        </tr>
        <tr>
          <td>Volcán San Antonio</td>
          <td>1677</td>
        </tr>
        <tr>
          <td>Volcán San Martin</td>
          <td>1646</td>
        </tr>
        <tr>
          <td>Tajuya near El Paso</td>
          <td>1585</td>
        </tr>
        <tr>
          <td>Montaña Quemada</td>
          <td>1492</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <p>Table 1: Recent historic eruptions on La Palma</p>
  <p>Table 1 summarises the eruptions recorded since the colonization of
  the islands by Europeans in the late 1400s.</p>
  <p></p>
  <p>Figure 2: Map of La Palma</p>
  <p>La Palma is one of the west most islands in the Volcanic
  Archipelago of the Canary Islands (Figure 2).</p>
</sec>
<sec id="data-methods-nb-1">
  <title>4 Data &amp; Methods</title>
</sec>
<sec id="conclusion-nb-1">
  <title>5 Conclusion</title>
</sec>
<sec id="references-nb-1">
  <title>References</title>
  <p>Marrero, José, Alicia García, Manuel Berrocoso, Ángeles Llinares,
  Antonio Rodríguez-Losada, and R. Ortiz. 2019. “Strategies for the
  Development of Volcanic Hazard Maps in Monogenetic Volcanic Fields:
  The Example of La Palma (Canary Islands).” <italic>Journal of Applied
  Volcanology</italic> 8 (July).
  <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s13617-019-0085-5">https://doi.org/10.1186/s13617-019-0085-5</ext-link>.</p>
  </sec>
</sec>
</body>



<back>
</back>


</sub-article>

</article>